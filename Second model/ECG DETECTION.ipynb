{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rameshavinash94/Cardiovascular-Detection-using-ECG-images/blob/main/Merging_Scaled_1D_%26_Trying_Different_CLassification_ML_Models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIqvxE_BKjV6"
   },
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "C82bu1OsKnfC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from natsort import natsorted\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXx7SoC7qyRv"
   },
   "source": [
    "### **WORKING ON COMBING MULTIPLE LEAD FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sI0sFzAqPP8g"
   },
   "outputs": [],
   "source": [
    "#creating list to store file_names\n",
    "NORMAL_=[]\n",
    "MI_=[]\n",
    "PMI_=[]\n",
    "HB_=[]\n",
    "\n",
    "normal = 'E:\\Heart Disease/Normal Person ECG Images (284x12=3408)'\n",
    "abnormal = 'E:\\Heart Disease/ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n",
    "MI = 'E:\\Heart Disease/ECG Images of Myocardial Infarction Patients (240x12=2880)'\n",
    "MI_history = 'E:\\Heart Disease/ECG Images of Patient that have History of MI (172x12=2064)'\n",
    "\n",
    "Types_ECG = {'normal':normal,'Abnormal_hear_beat':abnormal,'MI':MI,'History_MI':MI_history}\n",
    "\n",
    "for types,folder in Types_ECG.items():\n",
    "  for files in os.listdir(folder):\n",
    "    if types=='normal':\n",
    "      NORMAL_.append(files)\n",
    "    elif types=='Abnormal_hear_beat':\n",
    "      HB_.append(files)\n",
    "    elif types=='MI':\n",
    "      MI_.append(files)\n",
    "    elif types=='History_MI':\n",
    "      PMI_.append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJL9qAFSUOsN",
    "outputId": "9a4817f5-ae50-4aaf-96fe-8cc945289ad7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal(1).jpg',\n",
       " 'Normal(2).jpg',\n",
       " 'Normal(3).jpg',\n",
       " 'Normal(4).jpg',\n",
       " 'Normal(5).jpg',\n",
       " 'Normal(6).jpg',\n",
       " 'Normal(7).jpg',\n",
       " 'Normal(8).jpg',\n",
       " 'Normal(9).jpg',\n",
       " 'Normal(10).jpg',\n",
       " 'Normal(11).jpg',\n",
       " 'Normal(12).jpg',\n",
       " 'Normal(13).jpg',\n",
       " 'Normal(14).jpg',\n",
       " 'Normal(15).jpg',\n",
       " 'Normal(16).jpg',\n",
       " 'Normal(17).jpg',\n",
       " 'Normal(18).jpg',\n",
       " 'Normal(19).jpg',\n",
       " 'Normal(20).jpg',\n",
       " 'Normal(21).jpg',\n",
       " 'Normal(22).jpg',\n",
       " 'Normal(23).jpg',\n",
       " 'Normal(24).jpg',\n",
       " 'Normal(25).jpg',\n",
       " 'Normal(26).jpg',\n",
       " 'Normal(27).jpg',\n",
       " 'Normal(28).jpg',\n",
       " 'Normal(29).jpg',\n",
       " 'Normal(30).jpg',\n",
       " 'Normal(31).jpg',\n",
       " 'Normal(32).jpg',\n",
       " 'Normal(33).jpg',\n",
       " 'Normal(34).jpg',\n",
       " 'Normal(35).jpg',\n",
       " 'Normal(36).jpg',\n",
       " 'Normal(37).jpg',\n",
       " 'Normal(38).jpg',\n",
       " 'Normal(39).jpg',\n",
       " 'Normal(40).jpg',\n",
       " 'Normal(41).jpg',\n",
       " 'Normal(42).jpg',\n",
       " 'Normal(43).jpg',\n",
       " 'Normal(44).jpg',\n",
       " 'Normal(45).jpg',\n",
       " 'Normal(46).jpg',\n",
       " 'Normal(47).jpg',\n",
       " 'Normal(48).jpg',\n",
       " 'Normal(49).jpg',\n",
       " 'Normal(50).jpg',\n",
       " 'Normal(51).jpg',\n",
       " 'Normal(52).jpg',\n",
       " 'Normal(53).jpg',\n",
       " 'Normal(54).jpg',\n",
       " 'Normal(55).jpg',\n",
       " 'Normal(56).jpg',\n",
       " 'Normal(57).jpg',\n",
       " 'Normal(58).jpg',\n",
       " 'Normal(59).jpg',\n",
       " 'Normal(60).jpg',\n",
       " 'Normal(61).jpg',\n",
       " 'Normal(62).jpg',\n",
       " 'Normal(63).jpg',\n",
       " 'Normal(64).jpg',\n",
       " 'Normal(65).jpg',\n",
       " 'Normal(66).jpg',\n",
       " 'Normal(67).jpg',\n",
       " 'Normal(68).jpg',\n",
       " 'Normal(69).jpg',\n",
       " 'Normal(70).jpg',\n",
       " 'Normal(71).jpg',\n",
       " 'Normal(72).jpg',\n",
       " 'Normal(73).jpg',\n",
       " 'Normal(74).jpg',\n",
       " 'Normal(75).jpg',\n",
       " 'Normal(76).jpg',\n",
       " 'Normal(77).jpg',\n",
       " 'Normal(78).jpg',\n",
       " 'Normal(79).jpg',\n",
       " 'Normal(80).jpg',\n",
       " 'Normal(81).jpg',\n",
       " 'Normal(82).jpg',\n",
       " 'Normal(83).jpg',\n",
       " 'Normal(84).jpg',\n",
       " 'Normal(85).jpg',\n",
       " 'Normal(86).jpg',\n",
       " 'Normal(87).jpg',\n",
       " 'Normal(88).jpg',\n",
       " 'Normal(89).jpg',\n",
       " 'Normal(90).jpg',\n",
       " 'Normal(91).jpg',\n",
       " 'Normal(92).jpg',\n",
       " 'Normal(93).jpg',\n",
       " 'Normal(94).jpg',\n",
       " 'Normal(95).jpg',\n",
       " 'Normal(96).jpg',\n",
       " 'Normal(97).jpg',\n",
       " 'Normal(98).jpg',\n",
       " 'Normal(99).jpg',\n",
       " 'Normal(100).jpg',\n",
       " 'Normal(101).jpg',\n",
       " 'Normal(102).jpg',\n",
       " 'Normal(103).jpg',\n",
       " 'Normal(104).jpg',\n",
       " 'Normal(105).jpg',\n",
       " 'Normal(106).jpg',\n",
       " 'Normal(107).jpg',\n",
       " 'Normal(108).jpg',\n",
       " 'Normal(109).jpg',\n",
       " 'Normal(110).jpg',\n",
       " 'Normal(111).jpg',\n",
       " 'Normal(112).jpg',\n",
       " 'Normal(113).jpg',\n",
       " 'Normal(114).jpg',\n",
       " 'Normal(115).jpg',\n",
       " 'Normal(116).jpg',\n",
       " 'Normal(117).jpg',\n",
       " 'Normal(118).jpg',\n",
       " 'Normal(119).jpg',\n",
       " 'Normal(120).jpg',\n",
       " 'Normal(121).jpg',\n",
       " 'Normal(122).jpg',\n",
       " 'Normal(123).jpg',\n",
       " 'Normal(124).jpg',\n",
       " 'Normal(125).jpg',\n",
       " 'Normal(126).jpg',\n",
       " 'Normal(127).jpg',\n",
       " 'Normal(128).jpg',\n",
       " 'Normal(129).jpg',\n",
       " 'Normal(130).jpg',\n",
       " 'Normal(131).jpg',\n",
       " 'Normal(132).jpg',\n",
       " 'Normal(133).jpg',\n",
       " 'Normal(134).jpg',\n",
       " 'Normal(135).jpg',\n",
       " 'Normal(136).jpg',\n",
       " 'Normal(137).jpg',\n",
       " 'Normal(138).jpg',\n",
       " 'Normal(139).jpg',\n",
       " 'Normal(140).jpg',\n",
       " 'Normal(141).jpg',\n",
       " 'Normal(142).jpg',\n",
       " 'Normal(143).jpg',\n",
       " 'Normal(144).jpg',\n",
       " 'Normal(145).jpg',\n",
       " 'Normal(146).jpg',\n",
       " 'Normal(147).jpg',\n",
       " 'Normal(148).jpg',\n",
       " 'Normal(149).jpg',\n",
       " 'Normal(150).jpg',\n",
       " 'Normal(151).jpg',\n",
       " 'Normal(152).jpg',\n",
       " 'Normal(153).jpg',\n",
       " 'Normal(154).jpg',\n",
       " 'Normal(155).jpg',\n",
       " 'Normal(156).jpg',\n",
       " 'Normal(157).jpg',\n",
       " 'Normal(158).jpg',\n",
       " 'Normal(159).jpg',\n",
       " 'Normal(160).jpg',\n",
       " 'Normal(161).jpg',\n",
       " 'Normal(162).jpg',\n",
       " 'Normal(163).jpg',\n",
       " 'Normal(164).jpg',\n",
       " 'Normal(165).jpg',\n",
       " 'Normal(166).jpg',\n",
       " 'Normal(167).jpg',\n",
       " 'Normal(168).jpg',\n",
       " 'Normal(169).jpg',\n",
       " 'Normal(170).jpg',\n",
       " 'Normal(171).jpg',\n",
       " 'Normal(172).jpg',\n",
       " 'Normal(173).jpg',\n",
       " 'Normal(174).jpg',\n",
       " 'Normal(175).jpg',\n",
       " 'Normal(176).jpg',\n",
       " 'Normal(177).jpg',\n",
       " 'Normal(178).jpg',\n",
       " 'Normal(179).jpg',\n",
       " 'Normal(180).jpg',\n",
       " 'Normal(181).jpg',\n",
       " 'Normal(182).jpg',\n",
       " 'Normal(183).jpg',\n",
       " 'Normal(184).jpg',\n",
       " 'Normal(185).jpg',\n",
       " 'Normal(186).jpg',\n",
       " 'Normal(187).jpg',\n",
       " 'Normal(188).jpg',\n",
       " 'Normal(189).jpg',\n",
       " 'Normal(190).jpg',\n",
       " 'Normal(191).jpg',\n",
       " 'Normal(192).jpg',\n",
       " 'Normal(193).jpg',\n",
       " 'Normal(194).jpg',\n",
       " 'Normal(195).jpg',\n",
       " 'Normal(196).jpg',\n",
       " 'Normal(197).jpg',\n",
       " 'Normal(198).jpg',\n",
       " 'Normal(199).jpg',\n",
       " 'Normal(200).jpg',\n",
       " 'Normal(201).jpg',\n",
       " 'Normal(202).jpg',\n",
       " 'Normal(203).jpg',\n",
       " 'Normal(204).jpg',\n",
       " 'Normal(205).jpg',\n",
       " 'Normal(206).jpg',\n",
       " 'Normal(207).jpg',\n",
       " 'Normal(208).jpg',\n",
       " 'Normal(209).jpg',\n",
       " 'Normal(210).jpg',\n",
       " 'Normal(211).jpg',\n",
       " 'Normal(212).jpg',\n",
       " 'Normal(213).jpg',\n",
       " 'Normal(214).jpg',\n",
       " 'Normal(215).jpg',\n",
       " 'Normal(216).jpg',\n",
       " 'Normal(217).jpg',\n",
       " 'Normal(218).jpg',\n",
       " 'Normal(219).jpg',\n",
       " 'Normal(220).jpg',\n",
       " 'Normal(221).jpg',\n",
       " 'Normal(222).jpg',\n",
       " 'Normal(223).jpg',\n",
       " 'Normal(224).jpg',\n",
       " 'Normal(225).jpg',\n",
       " 'Normal(226).jpg',\n",
       " 'Normal(227).jpg',\n",
       " 'Normal(228).jpg',\n",
       " 'Normal(229).jpg',\n",
       " 'Normal(230).jpg',\n",
       " 'Normal(231).jpg',\n",
       " 'Normal(232).jpg',\n",
       " 'Normal(233).jpg',\n",
       " 'Normal(234).jpg',\n",
       " 'Normal(235).jpg',\n",
       " 'Normal(236).jpg',\n",
       " 'Normal(237).jpg',\n",
       " 'Normal(238).jpg',\n",
       " 'Normal(239).jpg',\n",
       " 'Normal(240).jpg',\n",
       " 'Normal(241).jpg',\n",
       " 'Normal(242).jpg',\n",
       " 'Normal(243).jpg',\n",
       " 'Normal(244).jpg',\n",
       " 'Normal(245).jpg',\n",
       " 'Normal(246).jpg',\n",
       " 'Normal(247).jpg',\n",
       " 'Normal(248).jpg',\n",
       " 'Normal(249).jpg',\n",
       " 'Normal(250).jpg',\n",
       " 'Normal(251).jpg',\n",
       " 'Normal(252).jpg',\n",
       " 'Normal(253).jpg',\n",
       " 'Normal(254).jpg',\n",
       " 'Normal(255).jpg',\n",
       " 'Normal(256).jpg',\n",
       " 'Normal(257).jpg',\n",
       " 'Normal(258).jpg',\n",
       " 'Normal(259).jpg',\n",
       " 'Normal(260).jpg',\n",
       " 'Normal(261).jpg',\n",
       " 'Normal(262).jpg',\n",
       " 'Normal(263).jpg',\n",
       " 'Normal(264).jpg',\n",
       " 'Normal(265).jpg',\n",
       " 'Normal(266).jpg',\n",
       " 'Normal(267).jpg',\n",
       " 'Normal(268).jpg',\n",
       " 'Normal(269).jpg',\n",
       " 'Normal(270).jpg',\n",
       " 'Normal(271).jpg',\n",
       " 'Normal(272).jpg',\n",
       " 'Normal(273).jpg',\n",
       " 'Normal(274).jpg',\n",
       " 'Normal(275).jpg',\n",
       " 'Normal(276).jpg',\n",
       " 'Normal(277).jpg',\n",
       " 'Normal(278).jpg',\n",
       " 'Normal(279).jpg',\n",
       " 'Normal(280).jpg',\n",
       " 'Normal(281).jpg',\n",
       " 'Normal(282).jpg',\n",
       " 'Normal(283).jpg',\n",
       " 'Normal(284).jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NORMAL_ = natsorted(NORMAL_)\n",
    "NORMAL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRbNR2HEUkvU",
    "outputId": "0cd461c0-5fe2-463a-cbf5-6325662d9011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MI(1).jpg',\n",
       " 'MI(2).jpg',\n",
       " 'MI(3).jpg',\n",
       " 'MI(4).jpg',\n",
       " 'MI(5).jpg',\n",
       " 'MI(6).jpg',\n",
       " 'MI(7).jpg',\n",
       " 'MI(8).jpg',\n",
       " 'MI(9).jpg',\n",
       " 'MI(10).jpg',\n",
       " 'MI(11).jpg',\n",
       " 'MI(12).jpg',\n",
       " 'MI(13).jpg',\n",
       " 'MI(14).jpg',\n",
       " 'MI(15).jpg',\n",
       " 'MI(16).jpg',\n",
       " 'MI(17).jpg',\n",
       " 'MI(18).jpg',\n",
       " 'MI(19).jpg',\n",
       " 'MI(20).jpg',\n",
       " 'MI(21).jpg',\n",
       " 'MI(22).jpg',\n",
       " 'MI(23).jpg',\n",
       " 'MI(24).jpg',\n",
       " 'MI(25).jpg',\n",
       " 'MI(26).jpg',\n",
       " 'MI(27).jpg',\n",
       " 'MI(28).jpg',\n",
       " 'MI(29).jpg',\n",
       " 'MI(30).jpg',\n",
       " 'MI(31).jpg',\n",
       " 'MI(32).jpg',\n",
       " 'MI(33).jpg',\n",
       " 'MI(34).jpg',\n",
       " 'MI(35).jpg',\n",
       " 'MI(36).jpg',\n",
       " 'MI(37).jpg',\n",
       " 'MI(38).jpg',\n",
       " 'MI(39).jpg',\n",
       " 'MI(40).jpg',\n",
       " 'MI(41).jpg',\n",
       " 'MI(42).jpg',\n",
       " 'MI(43).jpg',\n",
       " 'MI(44).jpg',\n",
       " 'MI(45).jpg',\n",
       " 'MI(46).jpg',\n",
       " 'MI(47).jpg',\n",
       " 'MI(48).jpg',\n",
       " 'MI(49).jpg',\n",
       " 'MI(50).jpg',\n",
       " 'MI(51).jpg',\n",
       " 'MI(52).jpg',\n",
       " 'MI(53).jpg',\n",
       " 'MI(54).jpg',\n",
       " 'MI(55).jpg',\n",
       " 'MI(56).jpg',\n",
       " 'MI(57).jpg',\n",
       " 'MI(58).jpg',\n",
       " 'MI(59).jpg',\n",
       " 'MI(60).jpg',\n",
       " 'MI(61).jpg',\n",
       " 'MI(62).jpg',\n",
       " 'MI(63).jpg',\n",
       " 'MI(64).jpg',\n",
       " 'MI(65).jpg',\n",
       " 'MI(66).jpg',\n",
       " 'MI(67).jpg',\n",
       " 'MI(68).jpg',\n",
       " 'MI(69).jpg',\n",
       " 'MI(70).jpg',\n",
       " 'MI(71).jpg',\n",
       " 'MI(72).jpg',\n",
       " 'MI(73).jpg',\n",
       " 'MI(74).jpg',\n",
       " 'MI(75).jpg',\n",
       " 'MI(76).jpg',\n",
       " 'MI(77).jpg',\n",
       " 'MI(78).jpg',\n",
       " 'MI(79).jpg',\n",
       " 'MI(80).jpg',\n",
       " 'MI(81).jpg',\n",
       " 'MI(82).jpg',\n",
       " 'MI(83).jpg',\n",
       " 'MI(84).jpg',\n",
       " 'MI(85).jpg',\n",
       " 'MI(86).jpg',\n",
       " 'MI(87).jpg',\n",
       " 'MI(88).jpg',\n",
       " 'MI(89).jpg',\n",
       " 'MI(90).jpg',\n",
       " 'MI(91).jpg',\n",
       " 'MI(92).jpg',\n",
       " 'MI(93).jpg',\n",
       " 'MI(94).jpg',\n",
       " 'MI(95).jpg',\n",
       " 'MI(96).jpg',\n",
       " 'MI(97).jpg',\n",
       " 'MI(98).jpg',\n",
       " 'MI(99).jpg',\n",
       " 'MI(100).jpg',\n",
       " 'MI(101).jpg',\n",
       " 'MI(102).jpg',\n",
       " 'MI(103).jpg',\n",
       " 'MI(104).jpg',\n",
       " 'MI(105).jpg',\n",
       " 'MI(106).jpg',\n",
       " 'MI(107).jpg',\n",
       " 'MI(108).jpg',\n",
       " 'MI(109).jpg',\n",
       " 'MI(110).jpg',\n",
       " 'MI(111).jpg',\n",
       " 'MI(112).jpg',\n",
       " 'MI(113).jpg',\n",
       " 'MI(114).jpg',\n",
       " 'MI(115).jpg',\n",
       " 'MI(116).jpg',\n",
       " 'MI(117).jpg',\n",
       " 'MI(118).jpg',\n",
       " 'MI(119).jpg',\n",
       " 'MI(120).jpg',\n",
       " 'MI(121).jpg',\n",
       " 'MI(122).jpg',\n",
       " 'MI(123).jpg',\n",
       " 'MI(124).jpg',\n",
       " 'MI(125).jpg',\n",
       " 'MI(126).jpg',\n",
       " 'MI(127).jpg',\n",
       " 'MI(128).jpg',\n",
       " 'MI(129).jpg',\n",
       " 'MI(130).jpg',\n",
       " 'MI(131).jpg',\n",
       " 'MI(132).jpg',\n",
       " 'MI(133).jpg',\n",
       " 'MI(134).jpg',\n",
       " 'MI(135).jpg',\n",
       " 'MI(136).jpg',\n",
       " 'MI(137).jpg',\n",
       " 'MI(138).jpg',\n",
       " 'MI(139).jpg',\n",
       " 'MI(140).jpg',\n",
       " 'MI(141).jpg',\n",
       " 'MI(142).jpg',\n",
       " 'MI(143).jpg',\n",
       " 'MI(144).jpg',\n",
       " 'MI(145).jpg',\n",
       " 'MI(146).jpg',\n",
       " 'MI(147).jpg',\n",
       " 'MI(148).jpg',\n",
       " 'MI(149).jpg',\n",
       " 'MI(150).jpg',\n",
       " 'MI(151).jpg',\n",
       " 'MI(152).jpg',\n",
       " 'MI(153).jpg',\n",
       " 'MI(154).jpg',\n",
       " 'MI(155).jpg',\n",
       " 'MI(156).jpg',\n",
       " 'MI(157).jpg',\n",
       " 'MI(158).jpg',\n",
       " 'MI(159).jpg',\n",
       " 'MI(160).jpg',\n",
       " 'MI(161).jpg',\n",
       " 'MI(162).jpg',\n",
       " 'MI(163).jpg',\n",
       " 'MI(164).jpg',\n",
       " 'MI(165).jpg',\n",
       " 'MI(166).jpg',\n",
       " 'MI(167).jpg',\n",
       " 'MI(168).jpg',\n",
       " 'MI(169).jpg',\n",
       " 'MI(170).jpg',\n",
       " 'MI(171).jpg',\n",
       " 'MI(172).jpg',\n",
       " 'MI(173).jpg',\n",
       " 'MI(174).jpg',\n",
       " 'MI(175).jpg',\n",
       " 'MI(176).jpg',\n",
       " 'MI(177).jpg',\n",
       " 'MI(178).jpg',\n",
       " 'MI(179).jpg',\n",
       " 'MI(180).jpg',\n",
       " 'MI(181).jpg',\n",
       " 'MI(182).jpg',\n",
       " 'MI(183).jpg',\n",
       " 'MI(184).jpg',\n",
       " 'MI(185).jpg',\n",
       " 'MI(186).jpg',\n",
       " 'MI(187).jpg',\n",
       " 'MI(188).jpg',\n",
       " 'MI(189).jpg',\n",
       " 'MI(190).jpg',\n",
       " 'MI(191).jpg',\n",
       " 'MI(192).jpg',\n",
       " 'MI(193).jpg',\n",
       " 'MI(194).jpg',\n",
       " 'MI(195).jpg',\n",
       " 'MI(196).jpg',\n",
       " 'MI(197).jpg',\n",
       " 'MI(198).jpg',\n",
       " 'MI(199).jpg',\n",
       " 'MI(200).jpg',\n",
       " 'MI(201).jpg',\n",
       " 'MI(202).jpg',\n",
       " 'MI(203).jpg',\n",
       " 'MI(204).jpg',\n",
       " 'MI(205).jpg',\n",
       " 'MI(206).jpg',\n",
       " 'MI(207).jpg',\n",
       " 'MI(208).jpg',\n",
       " 'MI(209).jpg',\n",
       " 'MI(210).jpg',\n",
       " 'MI(211).jpg',\n",
       " 'MI(212).jpg',\n",
       " 'MI(213).jpg',\n",
       " 'MI(214).jpg',\n",
       " 'MI(216).jpg',\n",
       " 'MI(217).jpg',\n",
       " 'MI(218).jpg',\n",
       " 'MI(219).jpg',\n",
       " 'MI(220).jpg',\n",
       " 'MI(221).jpg',\n",
       " 'MI(222).jpg',\n",
       " 'MI(223).jpg',\n",
       " 'MI(224).jpg',\n",
       " 'MI(225).jpg',\n",
       " 'MI(226).jpg',\n",
       " 'MI(227).jpg',\n",
       " 'MI(228).jpg',\n",
       " 'MI(229).jpg',\n",
       " 'MI(230).jpg',\n",
       " 'MI(231).jpg',\n",
       " 'MI(232).jpg',\n",
       " 'MI(233).jpg',\n",
       " 'MI(234).jpg',\n",
       " 'MI(235).jpg',\n",
       " 'MI(236).jpg',\n",
       " 'MI(237).jpg',\n",
       " 'MI(238).jpg',\n",
       " 'MI(239).jpg',\n",
       " 'MI(240).jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_ = natsorted(MI_)\n",
    "MI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4LMfTU3UuCM",
    "outputId": "0c127e8e-62b7-4015-e3ee-a34860e4f5ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PMI(1).jpg',\n",
       " 'PMI(2).jpg',\n",
       " 'PMI(3).jpg',\n",
       " 'PMI(4).jpg',\n",
       " 'PMI(5).jpg',\n",
       " 'PMI(6).jpg',\n",
       " 'PMI(7).jpg',\n",
       " 'PMI(8).jpg',\n",
       " 'PMI(9).jpg',\n",
       " 'PMI(10).jpg',\n",
       " 'PMI(11).jpg',\n",
       " 'PMI(12).jpg',\n",
       " 'PMI(13).jpg',\n",
       " 'PMI(14).jpg',\n",
       " 'PMI(15).jpg',\n",
       " 'PMI(16).jpg',\n",
       " 'PMI(17).jpg',\n",
       " 'PMI(18).jpg',\n",
       " 'PMI(19).jpg',\n",
       " 'PMI(20).jpg',\n",
       " 'PMI(21).jpg',\n",
       " 'PMI(22).jpg',\n",
       " 'PMI(23).jpg',\n",
       " 'PMI(24).jpg',\n",
       " 'PMI(25).jpg',\n",
       " 'PMI(26).jpg',\n",
       " 'PMI(27).jpg',\n",
       " 'PMI(28).jpg',\n",
       " 'PMI(29).jpg',\n",
       " 'PMI(30).jpg',\n",
       " 'PMI(31).jpg',\n",
       " 'PMI(32).jpg',\n",
       " 'PMI(33).jpg',\n",
       " 'PMI(34).jpg',\n",
       " 'PMI(35).jpg',\n",
       " 'PMI(36).jpg',\n",
       " 'PMI(37).jpg',\n",
       " 'PMI(38).jpg',\n",
       " 'PMI(39).jpg',\n",
       " 'PMI(40).jpg',\n",
       " 'PMI(41).jpg',\n",
       " 'PMI(42).jpg',\n",
       " 'PMI(43).jpg',\n",
       " 'PMI(44).jpg',\n",
       " 'PMI(45).jpg',\n",
       " 'PMI(46).jpg',\n",
       " 'PMI(47).jpg',\n",
       " 'PMI(48).jpg',\n",
       " 'PMI(49).jpg',\n",
       " 'PMI(50).jpg',\n",
       " 'PMI(51).jpg',\n",
       " 'PMI(52).jpg',\n",
       " 'PMI(53).jpg',\n",
       " 'PMI(54).jpg',\n",
       " 'PMI(55).jpg',\n",
       " 'PMI(56).jpg',\n",
       " 'PMI(57).jpg',\n",
       " 'PMI(58).jpg',\n",
       " 'PMI(59).jpg',\n",
       " 'PMI(60).jpg',\n",
       " 'PMI(61).jpg',\n",
       " 'PMI(62).jpg',\n",
       " 'PMI(63).jpg',\n",
       " 'PMI(64).jpg',\n",
       " 'PMI(65).jpg',\n",
       " 'PMI(66).jpg',\n",
       " 'PMI(67).jpg',\n",
       " 'PMI(68).jpg',\n",
       " 'PMI(69).jpg',\n",
       " 'PMI(70).jpg',\n",
       " 'PMI(71).jpg',\n",
       " 'PMI(72).jpg',\n",
       " 'PMI(73).jpg',\n",
       " 'PMI(74).jpg',\n",
       " 'PMI(75).jpg',\n",
       " 'PMI(76).jpg',\n",
       " 'PMI(77).jpg',\n",
       " 'PMI(78).jpg',\n",
       " 'PMI(79).jpg',\n",
       " 'PMI(80).jpg',\n",
       " 'PMI(81).jpg',\n",
       " 'PMI(82).jpg',\n",
       " 'PMI(83).jpg',\n",
       " 'PMI(84).jpg',\n",
       " 'PMI(85).jpg',\n",
       " 'PMI(86).jpg',\n",
       " 'PMI(87).jpg',\n",
       " 'PMI(88).jpg',\n",
       " 'PMI(89).jpg',\n",
       " 'PMI(90).jpg',\n",
       " 'PMI(91).jpg',\n",
       " 'PMI(92).jpg',\n",
       " 'PMI(93).jpg',\n",
       " 'PMI(94).jpg',\n",
       " 'PMI(95).jpg',\n",
       " 'PMI(96).jpg',\n",
       " 'PMI(97).jpg',\n",
       " 'PMI(98).jpg',\n",
       " 'PMI(99).jpg',\n",
       " 'PMI(100).jpg',\n",
       " 'PMI(101).jpg',\n",
       " 'PMI(102).jpg',\n",
       " 'PMI(103).jpg',\n",
       " 'PMI(104).jpg',\n",
       " 'PMI(105).jpg',\n",
       " 'PMI(106).jpg',\n",
       " 'PMI(107).jpg',\n",
       " 'PMI(108).jpg',\n",
       " 'PMI(109).jpg',\n",
       " 'PMI(110).jpg',\n",
       " 'PMI(111).jpg',\n",
       " 'PMI(112).jpg',\n",
       " 'PMI(113).jpg',\n",
       " 'PMI(114).jpg',\n",
       " 'PMI(115).jpg',\n",
       " 'PMI(116).jpg',\n",
       " 'PMI(117).jpg',\n",
       " 'PMI(118).jpg',\n",
       " 'PMI(119).jpg',\n",
       " 'PMI(120).jpg',\n",
       " 'PMI(121).jpg',\n",
       " 'PMI(122).jpg',\n",
       " 'PMI(123).jpg',\n",
       " 'PMI(124).jpg',\n",
       " 'PMI(125).jpg',\n",
       " 'PMI(126).jpg',\n",
       " 'PMI(127).jpg',\n",
       " 'PMI(128).jpg',\n",
       " 'PMI(129).jpg',\n",
       " 'PMI(130).jpg',\n",
       " 'PMI(131).jpg',\n",
       " 'PMI(132).jpg',\n",
       " 'PMI(133).jpg',\n",
       " 'PMI(134).jpg',\n",
       " 'PMI(135).jpg',\n",
       " 'PMI(136).jpg',\n",
       " 'PMI(137).jpg',\n",
       " 'PMI(138).jpg',\n",
       " 'PMI(139).jpg',\n",
       " 'PMI(140).jpg',\n",
       " 'PMI(141).jpg',\n",
       " 'PMI(142).jpg',\n",
       " 'PMI(143).jpg',\n",
       " 'PMI(144).jpg',\n",
       " 'PMI(145).jpg',\n",
       " 'PMI(146).jpg',\n",
       " 'PMI(147).jpg',\n",
       " 'PMI(148).jpg',\n",
       " 'PMI(149).jpg',\n",
       " 'PMI(150).jpg',\n",
       " 'PMI(151).jpg',\n",
       " 'PMI(152).jpg',\n",
       " 'PMI(153).jpg',\n",
       " 'PMI(154).jpg',\n",
       " 'PMI(155).jpg',\n",
       " 'PMI(156).jpg',\n",
       " 'PMI(157).jpg',\n",
       " 'PMI(158).jpg',\n",
       " 'PMI(159).jpg',\n",
       " 'PMI(160).jpg',\n",
       " 'PMI(161).jpg',\n",
       " 'PMI(162).jpg',\n",
       " 'PMI(163).jpg',\n",
       " 'PMI(164).jpg',\n",
       " 'PMI(165).jpg',\n",
       " 'PMI(166).jpg',\n",
       " 'PMI(167).jpg',\n",
       " 'PMI(168).jpg',\n",
       " 'PMI(169).jpg',\n",
       " 'PMI(170).jpg',\n",
       " 'PMI(171).jpg',\n",
       " 'PMI(172).jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMI_ = natsorted(PMI_)\n",
    "PMI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OinhdMKtU5mf",
    "outputId": "52dd393b-76c2-44a9-e64e-4d428380ed8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HB(1).jpg',\n",
       " 'HB(2).jpg',\n",
       " 'HB(3).jpg',\n",
       " 'HB(4).jpg',\n",
       " 'HB(5).jpg',\n",
       " 'HB(6).jpg',\n",
       " 'HB(7).jpg',\n",
       " 'HB(8).jpg',\n",
       " 'HB(9).jpg',\n",
       " 'HB(10).jpg',\n",
       " 'HB(11).jpg',\n",
       " 'HB(12).jpg',\n",
       " 'HB(13).jpg',\n",
       " 'HB(14).jpg',\n",
       " 'HB(15).jpg',\n",
       " 'HB(16).jpg',\n",
       " 'HB(17).jpg',\n",
       " 'HB(18).jpg',\n",
       " 'HB(19).jpg',\n",
       " 'HB(20).jpg',\n",
       " 'HB(21).jpg',\n",
       " 'HB(22).jpg',\n",
       " 'HB(23).jpg',\n",
       " 'HB(24).jpg',\n",
       " 'HB(25).jpg',\n",
       " 'HB(26).jpg',\n",
       " 'HB(27).jpg',\n",
       " 'HB(28).jpg',\n",
       " 'HB(29).jpg',\n",
       " 'HB(30).jpg',\n",
       " 'HB(31).jpg',\n",
       " 'HB(32).jpg',\n",
       " 'HB(33).jpg',\n",
       " 'HB(34).jpg',\n",
       " 'HB(35).jpg',\n",
       " 'HB(36).jpg',\n",
       " 'HB(37).jpg',\n",
       " 'HB(38).jpg',\n",
       " 'HB(39).jpg',\n",
       " 'HB(40).jpg',\n",
       " 'HB(41).jpg',\n",
       " 'HB(42).jpg',\n",
       " 'HB(43).jpg',\n",
       " 'HB(44).jpg',\n",
       " 'HB(45).jpg',\n",
       " 'HB(46).jpg',\n",
       " 'HB(47).jpg',\n",
       " 'HB(48).jpg',\n",
       " 'HB(49).jpg',\n",
       " 'HB(50).jpg',\n",
       " 'HB(51).jpg',\n",
       " 'HB(52).jpg',\n",
       " 'HB(53).jpg',\n",
       " 'HB(54).jpg',\n",
       " 'HB(55).jpg',\n",
       " 'HB(56).jpg',\n",
       " 'HB(57).jpg',\n",
       " 'HB(58).jpg',\n",
       " 'HB(59).jpg',\n",
       " 'HB(60).jpg',\n",
       " 'HB(61).jpg',\n",
       " 'HB(62).jpg',\n",
       " 'HB(63).jpg',\n",
       " 'HB(64).jpg',\n",
       " 'HB(65).jpg',\n",
       " 'HB(66).jpg',\n",
       " 'HB(67).jpg',\n",
       " 'HB(68).jpg',\n",
       " 'HB(69).jpg',\n",
       " 'HB(70).jpg',\n",
       " 'HB(71).jpg',\n",
       " 'HB(72).jpg',\n",
       " 'HB(73).jpg',\n",
       " 'HB(74).jpg',\n",
       " 'HB(75).jpg',\n",
       " 'HB(76).jpg',\n",
       " 'HB(77).jpg',\n",
       " 'HB(78).jpg',\n",
       " 'HB(79).jpg',\n",
       " 'HB(80).jpg',\n",
       " 'HB(81).jpg',\n",
       " 'HB(82).jpg',\n",
       " 'HB(83).jpg',\n",
       " 'HB(84).jpg',\n",
       " 'HB(85).jpg',\n",
       " 'HB(86).jpg',\n",
       " 'HB(87).jpg',\n",
       " 'HB(88).jpg',\n",
       " 'HB(89).jpg',\n",
       " 'HB(90).jpg',\n",
       " 'HB(91).jpg',\n",
       " 'HB(92).jpg',\n",
       " 'HB(93).jpg',\n",
       " 'HB(94).jpg',\n",
       " 'HB(95).jpg',\n",
       " 'HB(96).jpg',\n",
       " 'HB(97).jpg',\n",
       " 'HB(98).jpg',\n",
       " 'HB(99).jpg',\n",
       " 'HB(100).jpg',\n",
       " 'HB(101).jpg',\n",
       " 'HB(102).jpg',\n",
       " 'HB(103).jpg',\n",
       " 'HB(104).jpg',\n",
       " 'HB(105).jpg',\n",
       " 'HB(106).jpg',\n",
       " 'HB(107).jpg',\n",
       " 'HB(108).jpg',\n",
       " 'HB(109).jpg',\n",
       " 'HB(110).jpg',\n",
       " 'HB(111).jpg',\n",
       " 'HB(112).jpg',\n",
       " 'HB(113).jpg',\n",
       " 'HB(114).jpg',\n",
       " 'HB(115).jpg',\n",
       " 'HB(116).jpg',\n",
       " 'HB(117).jpg',\n",
       " 'HB(118).jpg',\n",
       " 'HB(119).jpg',\n",
       " 'HB(120).jpg',\n",
       " 'HB(121).jpg',\n",
       " 'HB(122).jpg',\n",
       " 'HB(123).jpg',\n",
       " 'HB(124).jpg',\n",
       " 'HB(125).jpg',\n",
       " 'HB(126).jpg',\n",
       " 'HB(127).jpg',\n",
       " 'HB(128).jpg',\n",
       " 'HB(129).jpg',\n",
       " 'HB(130).jpg',\n",
       " 'HB(131).jpg',\n",
       " 'HB(132).jpg',\n",
       " 'HB(133).jpg',\n",
       " 'HB(134).jpg',\n",
       " 'HB(135).jpg',\n",
       " 'HB(136).jpg',\n",
       " 'HB(137).jpg',\n",
       " 'HB(138).jpg',\n",
       " 'HB(139).jpg',\n",
       " 'HB(140).jpg',\n",
       " 'HB(141).jpg',\n",
       " 'HB(142).jpg',\n",
       " 'HB(143).jpg',\n",
       " 'HB(144).jpg',\n",
       " 'HB(145).jpg',\n",
       " 'HB(146).jpg',\n",
       " 'HB(147).jpg',\n",
       " 'HB(148).jpg',\n",
       " 'HB(149).jpg',\n",
       " 'HB(150).jpg',\n",
       " 'HB(151).jpg',\n",
       " 'HB(152).jpg',\n",
       " 'HB(153).jpg',\n",
       " 'HB(154).jpg',\n",
       " 'HB(155).jpg',\n",
       " 'HB(156).jpg',\n",
       " 'HB(157).jpg',\n",
       " 'HB(158).jpg',\n",
       " 'HB(159).jpg',\n",
       " 'HB(160).jpg',\n",
       " 'HB(161).jpg',\n",
       " 'HB(162).jpg',\n",
       " 'HB(163).jpg',\n",
       " 'HB(164).jpg',\n",
       " 'HB(165).jpg',\n",
       " 'HB(166).jpg',\n",
       " 'HB(167).jpg',\n",
       " 'HB(168).jpg',\n",
       " 'HB(169).jpg',\n",
       " 'HB(170).jpg',\n",
       " 'HB(171).jpg',\n",
       " 'HB(172).jpg',\n",
       " 'HB(173).jpg',\n",
       " 'HB(174).jpg',\n",
       " 'HB(175).jpg',\n",
       " 'HB(176).jpg',\n",
       " 'HB(177).jpg',\n",
       " 'HB(178).jpg',\n",
       " 'HB(179).jpg',\n",
       " 'HB(180).jpg',\n",
       " 'HB(181).jpg',\n",
       " 'HB(182).jpg',\n",
       " 'HB(183).jpg',\n",
       " 'HB(184).jpg',\n",
       " 'HB(185).jpg',\n",
       " 'HB(186).jpg',\n",
       " 'HB(187).jpg',\n",
       " 'HB(188).jpg',\n",
       " 'HB(189).jpg',\n",
       " 'HB(190).jpg',\n",
       " 'HB(191).jpg',\n",
       " 'HB(192).jpg',\n",
       " 'HB(193).jpg',\n",
       " 'HB(194).jpg',\n",
       " 'HB(195).jpg',\n",
       " 'HB(196).jpg',\n",
       " 'HB(197).jpg',\n",
       " 'HB(198).jpg',\n",
       " 'HB(199).jpg',\n",
       " 'HB(200).jpg',\n",
       " 'HB(201).jpg',\n",
       " 'HB(202).jpg',\n",
       " 'HB(203).jpg',\n",
       " 'HB(204).jpg',\n",
       " 'HB(205).jpg',\n",
       " 'HB(206).jpg',\n",
       " 'HB(207).jpg',\n",
       " 'HB(208).jpg',\n",
       " 'HB(209).jpg',\n",
       " 'HB(210).jpg',\n",
       " 'HB(211).jpg',\n",
       " 'HB(212).jpg',\n",
       " 'HB(213).jpg',\n",
       " 'HB(214).jpg',\n",
       " 'HB(215).jpg',\n",
       " 'HB(216).jpg',\n",
       " 'HB(217).jpg',\n",
       " 'HB(218).jpg',\n",
       " 'HB(219).jpg',\n",
       " 'HB(220).jpg',\n",
       " 'HB(221).jpg',\n",
       " 'HB(222).jpg',\n",
       " 'HB(223).jpg',\n",
       " 'HB(224).jpg',\n",
       " 'HB(225).jpg',\n",
       " 'HB(226).jpg',\n",
       " 'HB(227).jpg',\n",
       " 'HB(228).jpg',\n",
       " 'HB(229).jpg',\n",
       " 'HB(230).jpg',\n",
       " 'HB(231).jpg',\n",
       " 'HB(232).jpg',\n",
       " 'HB(233).jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HB_ = natsorted(HB_)\n",
    "HB_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T4Ay50ch6Ru"
   },
   "source": [
    "#### **COMBINED CSV OF EACH LEAD(1-12) FROM ALL IMAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyTYwqJSX8Vh",
    "outputId": "b1c922e9-83f4-4d31-e5cd-d5b18a78acf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'HB', 'MI', 'PM'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now reading just lead1\n",
    "df=pd.read_csv('Combined_IDLead_1.csv')\n",
    "df['Target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nbSKpUc2angF"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001BE87013090>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.groupby('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "fX_uYtekhL_z",
    "outputId": "a6d14a8e-a75f-4b1b-f39f-7830cba4c581"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728449</td>\n",
       "      <td>0.680755</td>\n",
       "      <td>0.619010</td>\n",
       "      <td>0.645367</td>\n",
       "      <td>0.681570</td>\n",
       "      <td>0.732488</td>\n",
       "      <td>0.758448</td>\n",
       "      <td>0.750660</td>\n",
       "      <td>0.728282</td>\n",
       "      <td>0.707928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637260</td>\n",
       "      <td>0.664539</td>\n",
       "      <td>0.667226</td>\n",
       "      <td>0.637064</td>\n",
       "      <td>0.593287</td>\n",
       "      <td>0.545503</td>\n",
       "      <td>0.515049</td>\n",
       "      <td>0.563257</td>\n",
       "      <td>0.633581</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.957972</td>\n",
       "      <td>0.950695</td>\n",
       "      <td>0.941024</td>\n",
       "      <td>0.930501</td>\n",
       "      <td>0.913601</td>\n",
       "      <td>0.892244</td>\n",
       "      <td>0.868016</td>\n",
       "      <td>0.855127</td>\n",
       "      <td>0.835307</td>\n",
       "      <td>0.798640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778790</td>\n",
       "      <td>0.806883</td>\n",
       "      <td>0.818640</td>\n",
       "      <td>0.842472</td>\n",
       "      <td>0.866740</td>\n",
       "      <td>0.884152</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.911293</td>\n",
       "      <td>0.922903</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.661575</td>\n",
       "      <td>0.695790</td>\n",
       "      <td>0.741113</td>\n",
       "      <td>0.716666</td>\n",
       "      <td>0.595794</td>\n",
       "      <td>0.425022</td>\n",
       "      <td>0.286457</td>\n",
       "      <td>0.425022</td>\n",
       "      <td>0.611384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>0.165850</td>\n",
       "      <td>0.363445</td>\n",
       "      <td>0.549460</td>\n",
       "      <td>0.539346</td>\n",
       "      <td>0.522272</td>\n",
       "      <td>0.491668</td>\n",
       "      <td>0.454949</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.839213</td>\n",
       "      <td>0.861690</td>\n",
       "      <td>0.866457</td>\n",
       "      <td>0.865756</td>\n",
       "      <td>0.855027</td>\n",
       "      <td>0.855606</td>\n",
       "      <td>0.845561</td>\n",
       "      <td>0.843187</td>\n",
       "      <td>0.846784</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789156</td>\n",
       "      <td>0.793622</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>0.796739</td>\n",
       "      <td>0.804063</td>\n",
       "      <td>0.809944</td>\n",
       "      <td>0.801814</td>\n",
       "      <td>0.777322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917753</td>\n",
       "      <td>0.924369</td>\n",
       "      <td>0.873765</td>\n",
       "      <td>0.791381</td>\n",
       "      <td>0.699513</td>\n",
       "      <td>0.604927</td>\n",
       "      <td>0.500312</td>\n",
       "      <td>0.446012</td>\n",
       "      <td>0.528910</td>\n",
       "      <td>0.634068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200676</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.407225</td>\n",
       "      <td>0.507346</td>\n",
       "      <td>0.605953</td>\n",
       "      <td>0.699309</td>\n",
       "      <td>0.790334</td>\n",
       "      <td>0.856593</td>\n",
       "      <td>0.849957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0.874246</td>\n",
       "      <td>0.877014</td>\n",
       "      <td>0.864280</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.871349</td>\n",
       "      <td>0.912404</td>\n",
       "      <td>0.958148</td>\n",
       "      <td>0.977826</td>\n",
       "      <td>0.956314</td>\n",
       "      <td>0.926773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>0.926328</td>\n",
       "      <td>0.898749</td>\n",
       "      <td>0.855709</td>\n",
       "      <td>0.823132</td>\n",
       "      <td>0.815458</td>\n",
       "      <td>0.818083</td>\n",
       "      <td>0.829300</td>\n",
       "      <td>0.822382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0.829815</td>\n",
       "      <td>0.832084</td>\n",
       "      <td>0.852396</td>\n",
       "      <td>0.909665</td>\n",
       "      <td>0.988242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.821865</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>0.612039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429721</td>\n",
       "      <td>0.531567</td>\n",
       "      <td>0.642137</td>\n",
       "      <td>0.742063</td>\n",
       "      <td>0.833042</td>\n",
       "      <td>0.814867</td>\n",
       "      <td>0.777622</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.759294</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0.469048</td>\n",
       "      <td>0.417983</td>\n",
       "      <td>0.362322</td>\n",
       "      <td>0.351995</td>\n",
       "      <td>0.391493</td>\n",
       "      <td>0.418305</td>\n",
       "      <td>0.440135</td>\n",
       "      <td>0.444598</td>\n",
       "      <td>0.460402</td>\n",
       "      <td>0.506810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408587</td>\n",
       "      <td>0.401864</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>0.359590</td>\n",
       "      <td>0.325879</td>\n",
       "      <td>0.288894</td>\n",
       "      <td>0.293521</td>\n",
       "      <td>0.344504</td>\n",
       "      <td>0.399012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.682510</td>\n",
       "      <td>0.682286</td>\n",
       "      <td>0.641051</td>\n",
       "      <td>0.620212</td>\n",
       "      <td>0.608210</td>\n",
       "      <td>0.576331</td>\n",
       "      <td>0.603596</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.677964</td>\n",
       "      <td>0.720297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452247</td>\n",
       "      <td>0.450421</td>\n",
       "      <td>0.439278</td>\n",
       "      <td>0.439086</td>\n",
       "      <td>0.394417</td>\n",
       "      <td>0.441650</td>\n",
       "      <td>0.473909</td>\n",
       "      <td>0.539199</td>\n",
       "      <td>0.547146</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.792175</td>\n",
       "      <td>0.815695</td>\n",
       "      <td>0.819518</td>\n",
       "      <td>0.820559</td>\n",
       "      <td>0.847985</td>\n",
       "      <td>0.880933</td>\n",
       "      <td>0.902061</td>\n",
       "      <td>0.878266</td>\n",
       "      <td>0.838806</td>\n",
       "      <td>0.811795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737351</td>\n",
       "      <td>0.778845</td>\n",
       "      <td>0.805446</td>\n",
       "      <td>0.782640</td>\n",
       "      <td>0.751236</td>\n",
       "      <td>0.741331</td>\n",
       "      <td>0.718790</td>\n",
       "      <td>0.714504</td>\n",
       "      <td>0.691004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows Ã— 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.728449  0.680755  0.619010  0.645367  0.681570  0.732488  0.758448   \n",
       "1    0.957972  0.950695  0.941024  0.930501  0.913601  0.892244  0.868016   \n",
       "2    0.611084  0.661575  0.695790  0.741113  0.716666  0.595794  0.425022   \n",
       "3    0.839213  0.861690  0.866457  0.865756  0.855027  0.855606  0.845561   \n",
       "4    0.917753  0.924369  0.873765  0.791381  0.699513  0.604927  0.500312   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "923  0.874246  0.877014  0.864280  0.860505  0.871349  0.912404  0.958148   \n",
       "924  0.829815  0.832084  0.852396  0.909665  0.988242  1.000000  0.923323   \n",
       "925  0.469048  0.417983  0.362322  0.351995  0.391493  0.418305  0.440135   \n",
       "926  0.682510  0.682286  0.641051  0.620212  0.608210  0.576331  0.603596   \n",
       "927  0.792175  0.815695  0.819518  0.820559  0.847985  0.880933  0.902061   \n",
       "\n",
       "            7         8         9  ...       246       247       248  \\\n",
       "0    0.750660  0.728282  0.707928  ...  0.637260  0.664539  0.667226   \n",
       "1    0.855127  0.835307  0.798640  ...  0.778790  0.806883  0.818640   \n",
       "2    0.286457  0.425022  0.611384  ...  0.000000  0.042690  0.165850   \n",
       "3    0.843187  0.846784  0.824438  ...  0.789156  0.793622  0.787665   \n",
       "4    0.446012  0.528910  0.634068  ...  0.200676  0.300147  0.407225   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "923  0.977826  0.956314  0.926773  ...  0.908312  0.926328  0.898749   \n",
       "924  0.821865  0.721302  0.612039  ...  0.429721  0.531567  0.642137   \n",
       "925  0.444598  0.460402  0.506810  ...  0.408587  0.401864  0.387069   \n",
       "926  0.645714  0.677964  0.720297  ...  0.452247  0.450421  0.439278   \n",
       "927  0.878266  0.838806  0.811795  ...  0.737351  0.778845  0.805446   \n",
       "\n",
       "          249       250       251       252       253       254  target  \n",
       "0    0.637064  0.593287  0.545503  0.515049  0.563257  0.633581       2  \n",
       "1    0.842472  0.866740  0.884152  0.897196  0.911293  0.922903       2  \n",
       "2    0.363445  0.549460  0.539346  0.522272  0.491668  0.454949       2  \n",
       "3    0.794515  0.796739  0.804063  0.809944  0.801814  0.777322       2  \n",
       "4    0.507346  0.605953  0.699309  0.790334  0.856593  0.849957       2  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "923  0.855709  0.823132  0.815458  0.818083  0.829300  0.822382       3  \n",
       "924  0.742063  0.833042  0.814867  0.777622  0.760714  0.759294       3  \n",
       "925  0.359590  0.325879  0.288894  0.293521  0.344504  0.399012       3  \n",
       "926  0.439086  0.394417  0.441650  0.473909  0.539199  0.547146       3  \n",
       "927  0.782640  0.751236  0.741331  0.718790  0.714504  0.691004       3  \n",
       "\n",
       "[928 rows x 256 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert Target column values as Numeric using ngroups\n",
    "encode_target_label = df.groupby('Target').ngroup().rename(\"target\").to_frame()\n",
    "test_final  = df.merge(encode_target_label, left_index=True, right_index=True)\n",
    "test_final.drop(columns=['Target'],inplace=True)\n",
    "test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRvRDvfrivtE"
   },
   "source": [
    "#### **PERFORM DIMENSIONALITY REDUCTION JUST FOR CHECKING/UNDERSTANDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "id": "scVPRQ3TZBaW",
    "outputId": "0b606399-2d4a-40a0-b9e3-cd7592305d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of each component: [1.76145888e-01 9.50265614e-02 6.99060614e-02 6.15960001e-02\n",
      " 5.34876630e-02 4.23664893e-02 3.68320213e-02 3.38541791e-02\n",
      " 3.00884979e-02 2.90396728e-02 2.64962509e-02 2.42272738e-02\n",
      " 2.10221030e-02 1.99751559e-02 1.77321042e-02 1.63016802e-02\n",
      " 1.53898622e-02 1.48412074e-02 1.33644825e-02 1.19674074e-02\n",
      " 1.16813409e-02 1.05807650e-02 9.68875480e-03 9.47385060e-03\n",
      " 8.65347748e-03 8.47506998e-03 7.93382172e-03 7.30163338e-03\n",
      " 6.76380665e-03 6.36886390e-03 6.02004791e-03 5.46823032e-03\n",
      " 5.31229911e-03 4.97821789e-03 4.74686092e-03 4.46081684e-03\n",
      " 4.21254684e-03 4.01200243e-03 3.87246476e-03 3.52519084e-03\n",
      " 3.37596894e-03 3.26978336e-03 3.08241145e-03 2.96423495e-03\n",
      " 2.73419816e-03 2.50965698e-03 2.35335480e-03 2.25665349e-03\n",
      " 2.20141761e-03 1.96782025e-03 1.74343954e-03 1.70982830e-03\n",
      " 1.57456047e-03 1.53704487e-03 1.36768435e-03 1.33167096e-03\n",
      " 1.26444173e-03 1.20053330e-03 1.18738749e-03 1.08864087e-03\n",
      " 1.02824532e-03 9.11484783e-04 7.89962329e-04 7.59785111e-04\n",
      " 6.49920864e-04 6.27833793e-04 6.04784065e-04 5.45886708e-04\n",
      " 5.32310104e-04 4.97728350e-04 4.78393196e-04 4.50404968e-04\n",
      " 4.26173488e-04 4.09392358e-04 3.92601462e-04 3.70241592e-04\n",
      " 3.66854838e-04 3.38846639e-04 3.08205817e-04 3.00634180e-04\n",
      " 2.80363497e-04 2.67851024e-04 2.49661061e-04 2.40636669e-04\n",
      " 2.11563109e-04 2.03939199e-04 1.99023468e-04 1.83135215e-04\n",
      " 1.66812721e-04 1.65881369e-04 1.55957778e-04 1.39152201e-04\n",
      " 1.25334610e-04 1.22325753e-04 1.13655873e-04 1.09396416e-04\n",
      " 1.03059962e-04 9.93680201e-05 9.86703828e-05 9.43986301e-05]\n",
      "\n",
      " Total Variance Explained: 99.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.018578</td>\n",
       "      <td>1.148263</td>\n",
       "      <td>-0.589582</td>\n",
       "      <td>0.193617</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>-0.309400</td>\n",
       "      <td>-0.161566</td>\n",
       "      <td>0.478471</td>\n",
       "      <td>0.972403</td>\n",
       "      <td>-0.031832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>-0.002018</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>-0.062541</td>\n",
       "      <td>-0.026181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.098692</td>\n",
       "      <td>0.289832</td>\n",
       "      <td>-1.766388</td>\n",
       "      <td>1.076165</td>\n",
       "      <td>-0.261201</td>\n",
       "      <td>-0.820446</td>\n",
       "      <td>-0.474188</td>\n",
       "      <td>-0.515238</td>\n",
       "      <td>0.692389</td>\n",
       "      <td>1.501606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017181</td>\n",
       "      <td>0.060271</td>\n",
       "      <td>-0.007445</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>-0.035138</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275021</td>\n",
       "      <td>-0.451289</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>-0.426415</td>\n",
       "      <td>0.066133</td>\n",
       "      <td>0.692474</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>-0.035867</td>\n",
       "      <td>0.815855</td>\n",
       "      <td>-0.909473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>-0.042162</td>\n",
       "      <td>-0.028640</td>\n",
       "      <td>0.120540</td>\n",
       "      <td>-0.046755</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>0.046794</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.517085</td>\n",
       "      <td>1.662693</td>\n",
       "      <td>-1.021167</td>\n",
       "      <td>0.804267</td>\n",
       "      <td>-0.281985</td>\n",
       "      <td>0.518180</td>\n",
       "      <td>0.355748</td>\n",
       "      <td>-0.344235</td>\n",
       "      <td>-0.910867</td>\n",
       "      <td>-0.629517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.042277</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>-0.049908</td>\n",
       "      <td>-0.037737</td>\n",
       "      <td>-0.013716</td>\n",
       "      <td>-0.022479</td>\n",
       "      <td>0.024932</td>\n",
       "      <td>-0.035401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.152840</td>\n",
       "      <td>-1.046283</td>\n",
       "      <td>0.351278</td>\n",
       "      <td>1.100381</td>\n",
       "      <td>-1.613642</td>\n",
       "      <td>1.484188</td>\n",
       "      <td>-0.113277</td>\n",
       "      <td>-0.251152</td>\n",
       "      <td>0.179023</td>\n",
       "      <td>-0.233104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>0.055067</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.015182</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>0.043648</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>-0.027092</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>-1.321884</td>\n",
       "      <td>2.153021</td>\n",
       "      <td>0.788596</td>\n",
       "      <td>-1.304253</td>\n",
       "      <td>0.458186</td>\n",
       "      <td>-0.859346</td>\n",
       "      <td>-0.069127</td>\n",
       "      <td>-0.392796</td>\n",
       "      <td>0.755732</td>\n",
       "      <td>-0.584050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036834</td>\n",
       "      <td>0.077189</td>\n",
       "      <td>-0.043223</td>\n",
       "      <td>-0.031310</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.027213</td>\n",
       "      <td>-0.051027</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>-0.867163</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.940680</td>\n",
       "      <td>0.302648</td>\n",
       "      <td>-0.469672</td>\n",
       "      <td>-0.368255</td>\n",
       "      <td>1.065579</td>\n",
       "      <td>0.801522</td>\n",
       "      <td>0.690113</td>\n",
       "      <td>0.953008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>-0.093667</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>-0.028588</td>\n",
       "      <td>-0.009515</td>\n",
       "      <td>0.056012</td>\n",
       "      <td>-0.003441</td>\n",
       "      <td>-0.065863</td>\n",
       "      <td>-0.021608</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>3.753012</td>\n",
       "      <td>0.841636</td>\n",
       "      <td>-0.317393</td>\n",
       "      <td>-0.296117</td>\n",
       "      <td>0.593769</td>\n",
       "      <td>-0.255474</td>\n",
       "      <td>-0.057091</td>\n",
       "      <td>-0.072048</td>\n",
       "      <td>0.664386</td>\n",
       "      <td>-0.837668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007450</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>-0.026534</td>\n",
       "      <td>0.062832</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.012845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.603083</td>\n",
       "      <td>0.126259</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.283612</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>-0.156326</td>\n",
       "      <td>-0.068399</td>\n",
       "      <td>-0.184308</td>\n",
       "      <td>0.461063</td>\n",
       "      <td>-0.002047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>-0.013706</td>\n",
       "      <td>-0.079157</td>\n",
       "      <td>-0.008137</td>\n",
       "      <td>0.036125</td>\n",
       "      <td>-0.058325</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.067989</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>-1.452945</td>\n",
       "      <td>1.233599</td>\n",
       "      <td>0.439472</td>\n",
       "      <td>0.278517</td>\n",
       "      <td>0.165928</td>\n",
       "      <td>-0.171830</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.033859</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>-0.687583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>-0.030064</td>\n",
       "      <td>0.069017</td>\n",
       "      <td>-0.060845</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>-0.067627</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>-0.052687</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.018578  1.148263 -0.589582  0.193617  0.047950 -0.309400 -0.161566   \n",
       "1   -1.098692  0.289832 -1.766388  1.076165 -0.261201 -0.820446 -0.474188   \n",
       "2    0.275021 -0.451289  0.106750 -0.426415  0.066133  0.692474  0.634894   \n",
       "3   -1.517085  1.662693 -1.021167  0.804267 -0.281985  0.518180  0.355748   \n",
       "4   -0.152840 -1.046283  0.351278  1.100381 -1.613642  1.484188 -0.113277   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "923 -1.321884  2.153021  0.788596 -1.304253  0.458186 -0.859346 -0.069127   \n",
       "924 -0.867163 -0.040504  0.940680  0.302648 -0.469672 -0.368255  1.065579   \n",
       "925  3.753012  0.841636 -0.317393 -0.296117  0.593769 -0.255474 -0.057091   \n",
       "926  0.603083  0.126259  0.003433  0.283612  0.169559 -0.156326 -0.068399   \n",
       "927 -1.452945  1.233599  0.439472  0.278517  0.165928 -0.171830 -0.075000   \n",
       "\n",
       "            7         8         9  ...        91        92        93  \\\n",
       "0    0.478471  0.972403 -0.031832  ...  0.012894 -0.003993  0.024224   \n",
       "1   -0.515238  0.692389  1.501606  ... -0.017181  0.060271 -0.007445   \n",
       "2   -0.035867  0.815855 -0.909473  ...  0.045130 -0.042162 -0.028640   \n",
       "3   -0.344235 -0.910867 -0.629517  ...  0.000077  0.042277  0.017344   \n",
       "4   -0.251152  0.179023 -0.233104  ... -0.009386  0.055067  0.001487   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "923 -0.392796  0.755732 -0.584050  ... -0.036834  0.077189 -0.043223   \n",
       "924  0.801522  0.690113  0.953008  ...  0.012526 -0.093667  0.015642   \n",
       "925 -0.072048  0.664386 -0.837668  ... -0.007450 -0.006564 -0.004092   \n",
       "926 -0.184308  0.461063 -0.002047  ...  0.056675  0.022991 -0.013706   \n",
       "927  0.033859  0.004444 -0.687583  ...  0.010191 -0.030064  0.069017   \n",
       "\n",
       "           94        95        96        97        98        99  target  \n",
       "0    0.011128 -0.002018 -0.002930  0.006409 -0.062541 -0.026181       2  \n",
       "1    0.012929  0.000100  0.044302  0.035357 -0.035138  0.000679       2  \n",
       "2    0.120540 -0.046755 -0.023125 -0.023212  0.046794  0.006530       2  \n",
       "3   -0.049908 -0.037737 -0.013716 -0.022479  0.024932 -0.035401       2  \n",
       "4    0.030908  0.015182 -0.006133  0.043648  0.002530 -0.027092       2  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "923 -0.031310  0.007646 -0.027213 -0.051027 -0.007832  0.015332       3  \n",
       "924 -0.028588 -0.009515  0.056012 -0.003441 -0.065863 -0.021608       3  \n",
       "925  0.004843 -0.026534  0.062832  0.020288 -0.004214 -0.012845       3  \n",
       "926 -0.079157 -0.008137  0.036125 -0.058325  0.020517  0.067989       3  \n",
       "927 -0.060845  0.015756 -0.067627  0.006552 -0.052687 -0.027903       3  \n",
       "\n",
       "[928 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just for testing\n",
    "# Now Perform Dimensionality reduction (PCA) on that Dataframe and check\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#do PCA and choose componeents as 100\n",
    "pca = PCA(n_components=100)\n",
    "x_pca = pca.fit_transform(test_final.iloc[:,0:-1])\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "\n",
    "# Calculate the variance explained by priciple components\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print('Variance of each component:', pca.explained_variance_ratio_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))\n",
    "\n",
    "#store the new pca generated dimensions in a dataframe\n",
    "pca_df = pd.DataFrame(data = x_pca)\n",
    "target = pd.Series(test_final['target'], name='target')\n",
    "result_df = pd.concat([pca_df, target], axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "ErMVKLMrKBiJ",
    "outputId": "f7ccdbdd-773b-4a0e-d7de-d467d120a211"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.018578</td>\n",
       "      <td>1.148263</td>\n",
       "      <td>-0.589582</td>\n",
       "      <td>0.193617</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>-0.309400</td>\n",
       "      <td>-0.161566</td>\n",
       "      <td>0.478471</td>\n",
       "      <td>0.972403</td>\n",
       "      <td>-0.031832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>-0.002018</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>-0.062541</td>\n",
       "      <td>-0.026181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.098692</td>\n",
       "      <td>0.289832</td>\n",
       "      <td>-1.766388</td>\n",
       "      <td>1.076165</td>\n",
       "      <td>-0.261201</td>\n",
       "      <td>-0.820446</td>\n",
       "      <td>-0.474188</td>\n",
       "      <td>-0.515238</td>\n",
       "      <td>0.692389</td>\n",
       "      <td>1.501606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017181</td>\n",
       "      <td>0.060271</td>\n",
       "      <td>-0.007445</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>-0.035138</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275021</td>\n",
       "      <td>-0.451289</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>-0.426415</td>\n",
       "      <td>0.066133</td>\n",
       "      <td>0.692474</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>-0.035867</td>\n",
       "      <td>0.815855</td>\n",
       "      <td>-0.909473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>-0.042162</td>\n",
       "      <td>-0.028640</td>\n",
       "      <td>0.120540</td>\n",
       "      <td>-0.046755</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>0.046794</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.517085</td>\n",
       "      <td>1.662693</td>\n",
       "      <td>-1.021167</td>\n",
       "      <td>0.804267</td>\n",
       "      <td>-0.281985</td>\n",
       "      <td>0.518180</td>\n",
       "      <td>0.355748</td>\n",
       "      <td>-0.344235</td>\n",
       "      <td>-0.910867</td>\n",
       "      <td>-0.629517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.042277</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>-0.049908</td>\n",
       "      <td>-0.037737</td>\n",
       "      <td>-0.013716</td>\n",
       "      <td>-0.022479</td>\n",
       "      <td>0.024932</td>\n",
       "      <td>-0.035401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.152840</td>\n",
       "      <td>-1.046283</td>\n",
       "      <td>0.351278</td>\n",
       "      <td>1.100381</td>\n",
       "      <td>-1.613642</td>\n",
       "      <td>1.484188</td>\n",
       "      <td>-0.113277</td>\n",
       "      <td>-0.251152</td>\n",
       "      <td>0.179023</td>\n",
       "      <td>-0.233104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>0.055067</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.015182</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>0.043648</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>-0.027092</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>-1.321884</td>\n",
       "      <td>2.153021</td>\n",
       "      <td>0.788596</td>\n",
       "      <td>-1.304253</td>\n",
       "      <td>0.458186</td>\n",
       "      <td>-0.859346</td>\n",
       "      <td>-0.069127</td>\n",
       "      <td>-0.392796</td>\n",
       "      <td>0.755732</td>\n",
       "      <td>-0.584050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036834</td>\n",
       "      <td>0.077189</td>\n",
       "      <td>-0.043223</td>\n",
       "      <td>-0.031310</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.027213</td>\n",
       "      <td>-0.051027</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>-0.867163</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.940680</td>\n",
       "      <td>0.302648</td>\n",
       "      <td>-0.469672</td>\n",
       "      <td>-0.368255</td>\n",
       "      <td>1.065579</td>\n",
       "      <td>0.801522</td>\n",
       "      <td>0.690113</td>\n",
       "      <td>0.953008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>-0.093667</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>-0.028588</td>\n",
       "      <td>-0.009515</td>\n",
       "      <td>0.056012</td>\n",
       "      <td>-0.003441</td>\n",
       "      <td>-0.065863</td>\n",
       "      <td>-0.021608</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>3.753012</td>\n",
       "      <td>0.841636</td>\n",
       "      <td>-0.317393</td>\n",
       "      <td>-0.296117</td>\n",
       "      <td>0.593769</td>\n",
       "      <td>-0.255474</td>\n",
       "      <td>-0.057091</td>\n",
       "      <td>-0.072048</td>\n",
       "      <td>0.664386</td>\n",
       "      <td>-0.837668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007450</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>-0.026534</td>\n",
       "      <td>0.062832</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.012845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.603083</td>\n",
       "      <td>0.126259</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.283612</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>-0.156326</td>\n",
       "      <td>-0.068399</td>\n",
       "      <td>-0.184308</td>\n",
       "      <td>0.461063</td>\n",
       "      <td>-0.002047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>-0.013706</td>\n",
       "      <td>-0.079157</td>\n",
       "      <td>-0.008137</td>\n",
       "      <td>0.036125</td>\n",
       "      <td>-0.058325</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.067989</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>-1.452945</td>\n",
       "      <td>1.233599</td>\n",
       "      <td>0.439472</td>\n",
       "      <td>0.278517</td>\n",
       "      <td>0.165928</td>\n",
       "      <td>-0.171830</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.033859</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>-0.687583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>-0.030064</td>\n",
       "      <td>0.069017</td>\n",
       "      <td>-0.060845</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>-0.067627</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>-0.052687</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.018578  1.148263 -0.589582  0.193617  0.047950 -0.309400 -0.161566   \n",
       "1   -1.098692  0.289832 -1.766388  1.076165 -0.261201 -0.820446 -0.474188   \n",
       "2    0.275021 -0.451289  0.106750 -0.426415  0.066133  0.692474  0.634894   \n",
       "3   -1.517085  1.662693 -1.021167  0.804267 -0.281985  0.518180  0.355748   \n",
       "4   -0.152840 -1.046283  0.351278  1.100381 -1.613642  1.484188 -0.113277   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "923 -1.321884  2.153021  0.788596 -1.304253  0.458186 -0.859346 -0.069127   \n",
       "924 -0.867163 -0.040504  0.940680  0.302648 -0.469672 -0.368255  1.065579   \n",
       "925  3.753012  0.841636 -0.317393 -0.296117  0.593769 -0.255474 -0.057091   \n",
       "926  0.603083  0.126259  0.003433  0.283612  0.169559 -0.156326 -0.068399   \n",
       "927 -1.452945  1.233599  0.439472  0.278517  0.165928 -0.171830 -0.075000   \n",
       "\n",
       "            7         8         9  ...        91        92        93  \\\n",
       "0    0.478471  0.972403 -0.031832  ...  0.012894 -0.003993  0.024224   \n",
       "1   -0.515238  0.692389  1.501606  ... -0.017181  0.060271 -0.007445   \n",
       "2   -0.035867  0.815855 -0.909473  ...  0.045130 -0.042162 -0.028640   \n",
       "3   -0.344235 -0.910867 -0.629517  ...  0.000077  0.042277  0.017344   \n",
       "4   -0.251152  0.179023 -0.233104  ... -0.009386  0.055067  0.001487   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "923 -0.392796  0.755732 -0.584050  ... -0.036834  0.077189 -0.043223   \n",
       "924  0.801522  0.690113  0.953008  ...  0.012526 -0.093667  0.015642   \n",
       "925 -0.072048  0.664386 -0.837668  ... -0.007450 -0.006564 -0.004092   \n",
       "926 -0.184308  0.461063 -0.002047  ...  0.056675  0.022991 -0.013706   \n",
       "927  0.033859  0.004444 -0.687583  ...  0.010191 -0.030064  0.069017   \n",
       "\n",
       "           94        95        96        97        98        99  target  \n",
       "0    0.011128 -0.002018 -0.002930  0.006409 -0.062541 -0.026181       2  \n",
       "1    0.012929  0.000100  0.044302  0.035357 -0.035138  0.000679       2  \n",
       "2    0.120540 -0.046755 -0.023125 -0.023212  0.046794  0.006530       2  \n",
       "3   -0.049908 -0.037737 -0.013716 -0.022479  0.024932 -0.035401       2  \n",
       "4    0.030908  0.015182 -0.006133  0.043648  0.002530 -0.027092       2  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "923 -0.031310  0.007646 -0.027213 -0.051027 -0.007832  0.015332       3  \n",
       "924 -0.028588 -0.009515  0.056012 -0.003441 -0.065863 -0.021608       3  \n",
       "925  0.004843 -0.026534  0.062832  0.020288 -0.004214 -0.012845       3  \n",
       "926 -0.079157 -0.008137  0.036125 -0.058325  0.020517  0.067989       3  \n",
       "927 -0.060845  0.015756 -0.067627  0.006552 -0.052687 -0.027903       3  \n",
       "\n",
       "[928 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UOI2lH6iOIY"
   },
   "source": [
    "#### **TRYING DIFFERENT ML MODELS ON A SINGLE LEAD(EX : 1) POST DIMENSIONALITY REDUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE3l8LNQizo0"
   },
   "source": [
    "##### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Me4jqP4Zih_I",
    "outputId": "83dde896-7166-44cb-b88f-725eaedb9d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782258064516129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73       105\n",
      "           1       0.91      0.91      0.91        94\n",
      "           2       0.72      0.88      0.79       112\n",
      "           3       0.63      0.67      0.65        61\n",
      "\n",
      "    accuracy                           0.78       372\n",
      "   macro avg       0.78      0.77      0.77       372\n",
      "weighted avg       0.80      0.78      0.78       372\n",
      "\n",
      "Tuned Model Parameters: {'knn__n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for ML model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Setup the pipeline steps:\n",
    "steps = [('knn', KNeighborsClassifier())]\n",
    "        \n",
    "# Create the pipeline: pipeline \n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# have paased less range value of hyperparamter since i'm using free tier version of google colab.\n",
    "k_range = list(range(1, 9))\n",
    "parameters = dict(knn__n_neighbors=k_range)\n",
    "\n",
    "#input\n",
    "X = result_df.iloc[:,0:-1]\n",
    "\n",
    "#target\n",
    "y=result_df.iloc[:,-1]\n",
    "\n",
    "# Create train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "#increasing cv score takes lot of time in gooogle colab, so kept it just 2.\n",
    "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
    "\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "Knn_Accuracy = cv.score(X_test, y_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(Knn_Accuracy))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDkFlXChia-8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKtMbgXLifbX"
   },
   "source": [
    "##### **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BbGt_eOVkJq6"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Setup the pipeline steps:\n",
    "steps = [('lr', LogisticRegression())]\n",
    "        \n",
    "# Create the pipeline: pipeline \n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#input\n",
    "X = result_df.iloc[:,0:-1]\n",
    "\n",
    "#target\n",
    "y=result_df.iloc[:,-1]\n",
    "\n",
    "#parameters for gridsearchcv if we increase range of entries from 5 to higher value, we can get greater accurange\n",
    "c_space = np.logspace(-4, 4, 3)\n",
    "parameters = {'lr__C': c_space,'lr__penalty': ['l2']} \n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "#call GridSearchCV and set crossvalscore to 2\n",
    "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
    "\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "LR_Accuracy = cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3k9i12eGunX1",
    "outputId": "21ce6e7f-653e-4710-d585-ff445736e08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5510752688172043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.34      0.36       105\n",
      "           1       0.73      0.91      0.81        94\n",
      "           2       0.57      0.57      0.57       112\n",
      "           3       0.42      0.31      0.36        61\n",
      "\n",
      "    accuracy                           0.55       372\n",
      "   macro avg       0.52      0.54      0.52       372\n",
      "weighted avg       0.53      0.55      0.54       372\n",
      "\n",
      "Tuned Model Parameters: {'lr__C': 10000.0, 'lr__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(LR_Accuracy))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W0sQQDwiisE"
   },
   "source": [
    "##### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94xczE1iurC9",
    "outputId": "d5530fa8-865f-4ec0-80c9-f89940866c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225806451612904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74        93\n",
      "           1       1.00      1.00      1.00        99\n",
      "           2       1.00      0.61      0.76       117\n",
      "           3       1.00      0.68      0.81        63\n",
      "\n",
      "    accuracy                           0.82       372\n",
      "   macro avg       0.90      0.82      0.83       372\n",
      "weighted avg       0.90      0.82      0.83       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for ML model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Setup the pipeline\n",
    "steps = [('SVM', SVC())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#input\n",
    "X = result_df.iloc[:,0:-1]\n",
    "\n",
    "#target\n",
    "y=result_df.iloc[:,-1]\n",
    "\n",
    "# Specify the hyperparameter space, if we increase the penalty(c) and gamma value the accurancy can be increased.\n",
    "#since it takes lots of time in google colab provided only a single value\n",
    "parameters = {'SVM__C':[10],'SVM__gamma':[1]}\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=21)\n",
    "\n",
    "cv = GridSearchCV(pipeline,parameters,cv=3)\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "SVM_Accuracy = cv.score(X_test, y_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "SVM_Accuracy=cv.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy: {}\".format(SVM_Accuracy))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1GNZtOUi6PP"
   },
   "source": [
    "#### **NOW COMBINING ALL 12 LEADS INTO A SINGLE CSV FILE AND THEN PERFROM MODEL ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "huNy0hsWSkr5",
    "outputId": "ae4fc5c3-8b46-4d0a-d075-c2c64559680c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done but there error\n"
     ]
    }
   ],
   "source": [
    "#lets try combining all 12 leads in a single csv\n",
    "location= 'â€ªE:\\Heart Disease/Compind/'\n",
    "try:\n",
    "    for files in natsorted(os.listdir(location)):\n",
    "      if files.endswith(\".csv\") and not files.endswith(\"13.csv\"):\n",
    "        if files!='Combined_IDLead_1.csv':\n",
    "          df=pd.read_csv('â€ªE:/Heart Disease/Compind/{}'.format(files))\n",
    "          df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "          test_final=pd.concat([test_final,df],axis=1,ignore_index=True)\n",
    "          test_final.drop(columns=test_final.columns[-1],axis=1,inplace=True)\n",
    "        print('Done test_final')\n",
    "except:\n",
    "    print('Done but there error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OZ6_Lg0180y3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728449</td>\n",
       "      <td>0.680755</td>\n",
       "      <td>0.619010</td>\n",
       "      <td>0.645367</td>\n",
       "      <td>0.681570</td>\n",
       "      <td>0.732488</td>\n",
       "      <td>0.758448</td>\n",
       "      <td>0.750660</td>\n",
       "      <td>0.728282</td>\n",
       "      <td>0.707928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637260</td>\n",
       "      <td>0.664539</td>\n",
       "      <td>0.667226</td>\n",
       "      <td>0.637064</td>\n",
       "      <td>0.593287</td>\n",
       "      <td>0.545503</td>\n",
       "      <td>0.515049</td>\n",
       "      <td>0.563257</td>\n",
       "      <td>0.633581</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.957972</td>\n",
       "      <td>0.950695</td>\n",
       "      <td>0.941024</td>\n",
       "      <td>0.930501</td>\n",
       "      <td>0.913601</td>\n",
       "      <td>0.892244</td>\n",
       "      <td>0.868016</td>\n",
       "      <td>0.855127</td>\n",
       "      <td>0.835307</td>\n",
       "      <td>0.798640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778790</td>\n",
       "      <td>0.806883</td>\n",
       "      <td>0.818640</td>\n",
       "      <td>0.842472</td>\n",
       "      <td>0.866740</td>\n",
       "      <td>0.884152</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.911293</td>\n",
       "      <td>0.922903</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.661575</td>\n",
       "      <td>0.695790</td>\n",
       "      <td>0.741113</td>\n",
       "      <td>0.716666</td>\n",
       "      <td>0.595794</td>\n",
       "      <td>0.425022</td>\n",
       "      <td>0.286457</td>\n",
       "      <td>0.425022</td>\n",
       "      <td>0.611384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>0.165850</td>\n",
       "      <td>0.363445</td>\n",
       "      <td>0.549460</td>\n",
       "      <td>0.539346</td>\n",
       "      <td>0.522272</td>\n",
       "      <td>0.491668</td>\n",
       "      <td>0.454949</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.839213</td>\n",
       "      <td>0.861690</td>\n",
       "      <td>0.866457</td>\n",
       "      <td>0.865756</td>\n",
       "      <td>0.855027</td>\n",
       "      <td>0.855606</td>\n",
       "      <td>0.845561</td>\n",
       "      <td>0.843187</td>\n",
       "      <td>0.846784</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789156</td>\n",
       "      <td>0.793622</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>0.796739</td>\n",
       "      <td>0.804063</td>\n",
       "      <td>0.809944</td>\n",
       "      <td>0.801814</td>\n",
       "      <td>0.777322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917753</td>\n",
       "      <td>0.924369</td>\n",
       "      <td>0.873765</td>\n",
       "      <td>0.791381</td>\n",
       "      <td>0.699513</td>\n",
       "      <td>0.604927</td>\n",
       "      <td>0.500312</td>\n",
       "      <td>0.446012</td>\n",
       "      <td>0.528910</td>\n",
       "      <td>0.634068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200676</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.407225</td>\n",
       "      <td>0.507346</td>\n",
       "      <td>0.605953</td>\n",
       "      <td>0.699309</td>\n",
       "      <td>0.790334</td>\n",
       "      <td>0.856593</td>\n",
       "      <td>0.849957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0.874246</td>\n",
       "      <td>0.877014</td>\n",
       "      <td>0.864280</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.871349</td>\n",
       "      <td>0.912404</td>\n",
       "      <td>0.958148</td>\n",
       "      <td>0.977826</td>\n",
       "      <td>0.956314</td>\n",
       "      <td>0.926773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>0.926328</td>\n",
       "      <td>0.898749</td>\n",
       "      <td>0.855709</td>\n",
       "      <td>0.823132</td>\n",
       "      <td>0.815458</td>\n",
       "      <td>0.818083</td>\n",
       "      <td>0.829300</td>\n",
       "      <td>0.822382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0.829815</td>\n",
       "      <td>0.832084</td>\n",
       "      <td>0.852396</td>\n",
       "      <td>0.909665</td>\n",
       "      <td>0.988242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.821865</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>0.612039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429721</td>\n",
       "      <td>0.531567</td>\n",
       "      <td>0.642137</td>\n",
       "      <td>0.742063</td>\n",
       "      <td>0.833042</td>\n",
       "      <td>0.814867</td>\n",
       "      <td>0.777622</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.759294</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0.469048</td>\n",
       "      <td>0.417983</td>\n",
       "      <td>0.362322</td>\n",
       "      <td>0.351995</td>\n",
       "      <td>0.391493</td>\n",
       "      <td>0.418305</td>\n",
       "      <td>0.440135</td>\n",
       "      <td>0.444598</td>\n",
       "      <td>0.460402</td>\n",
       "      <td>0.506810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408587</td>\n",
       "      <td>0.401864</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>0.359590</td>\n",
       "      <td>0.325879</td>\n",
       "      <td>0.288894</td>\n",
       "      <td>0.293521</td>\n",
       "      <td>0.344504</td>\n",
       "      <td>0.399012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.682510</td>\n",
       "      <td>0.682286</td>\n",
       "      <td>0.641051</td>\n",
       "      <td>0.620212</td>\n",
       "      <td>0.608210</td>\n",
       "      <td>0.576331</td>\n",
       "      <td>0.603596</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.677964</td>\n",
       "      <td>0.720297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452247</td>\n",
       "      <td>0.450421</td>\n",
       "      <td>0.439278</td>\n",
       "      <td>0.439086</td>\n",
       "      <td>0.394417</td>\n",
       "      <td>0.441650</td>\n",
       "      <td>0.473909</td>\n",
       "      <td>0.539199</td>\n",
       "      <td>0.547146</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.792175</td>\n",
       "      <td>0.815695</td>\n",
       "      <td>0.819518</td>\n",
       "      <td>0.820559</td>\n",
       "      <td>0.847985</td>\n",
       "      <td>0.880933</td>\n",
       "      <td>0.902061</td>\n",
       "      <td>0.878266</td>\n",
       "      <td>0.838806</td>\n",
       "      <td>0.811795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737351</td>\n",
       "      <td>0.778845</td>\n",
       "      <td>0.805446</td>\n",
       "      <td>0.782640</td>\n",
       "      <td>0.751236</td>\n",
       "      <td>0.741331</td>\n",
       "      <td>0.718790</td>\n",
       "      <td>0.714504</td>\n",
       "      <td>0.691004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows Ã— 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.728449  0.680755  0.619010  0.645367  0.681570  0.732488  0.758448   \n",
       "1    0.957972  0.950695  0.941024  0.930501  0.913601  0.892244  0.868016   \n",
       "2    0.611084  0.661575  0.695790  0.741113  0.716666  0.595794  0.425022   \n",
       "3    0.839213  0.861690  0.866457  0.865756  0.855027  0.855606  0.845561   \n",
       "4    0.917753  0.924369  0.873765  0.791381  0.699513  0.604927  0.500312   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "923  0.874246  0.877014  0.864280  0.860505  0.871349  0.912404  0.958148   \n",
       "924  0.829815  0.832084  0.852396  0.909665  0.988242  1.000000  0.923323   \n",
       "925  0.469048  0.417983  0.362322  0.351995  0.391493  0.418305  0.440135   \n",
       "926  0.682510  0.682286  0.641051  0.620212  0.608210  0.576331  0.603596   \n",
       "927  0.792175  0.815695  0.819518  0.820559  0.847985  0.880933  0.902061   \n",
       "\n",
       "            7         8         9  ...       246       247       248  \\\n",
       "0    0.750660  0.728282  0.707928  ...  0.637260  0.664539  0.667226   \n",
       "1    0.855127  0.835307  0.798640  ...  0.778790  0.806883  0.818640   \n",
       "2    0.286457  0.425022  0.611384  ...  0.000000  0.042690  0.165850   \n",
       "3    0.843187  0.846784  0.824438  ...  0.789156  0.793622  0.787665   \n",
       "4    0.446012  0.528910  0.634068  ...  0.200676  0.300147  0.407225   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "923  0.977826  0.956314  0.926773  ...  0.908312  0.926328  0.898749   \n",
       "924  0.821865  0.721302  0.612039  ...  0.429721  0.531567  0.642137   \n",
       "925  0.444598  0.460402  0.506810  ...  0.408587  0.401864  0.387069   \n",
       "926  0.645714  0.677964  0.720297  ...  0.452247  0.450421  0.439278   \n",
       "927  0.878266  0.838806  0.811795  ...  0.737351  0.778845  0.805446   \n",
       "\n",
       "          249       250       251       252       253       254  target  \n",
       "0    0.637064  0.593287  0.545503  0.515049  0.563257  0.633581       2  \n",
       "1    0.842472  0.866740  0.884152  0.897196  0.911293  0.922903       2  \n",
       "2    0.363445  0.549460  0.539346  0.522272  0.491668  0.454949       2  \n",
       "3    0.794515  0.796739  0.804063  0.809944  0.801814  0.777322       2  \n",
       "4    0.507346  0.605953  0.699309  0.790334  0.856593  0.849957       2  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "923  0.855709  0.823132  0.815458  0.818083  0.829300  0.822382       3  \n",
       "924  0.742063  0.833042  0.814867  0.777622  0.760714  0.759294       3  \n",
       "925  0.359590  0.325879  0.288894  0.293521  0.344504  0.399012       3  \n",
       "926  0.439086  0.394417  0.441650  0.473909  0.539199  0.547146       3  \n",
       "927  0.782640  0.751236  0.741331  0.718790  0.714504  0.691004       3  \n",
       "\n",
       "[928 rows x 256 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write the final file to csv\n",
    "test_final.to_csv('final_1D.csv',header=False,index=False)\n",
    "test_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxWK-X-qjde2"
   },
   "source": [
    "#### **TEST DIMENSIONALITY REDUCTION EXPLAINED VARIANCE ON  THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WXvZGdh5cxrL",
    "outputId": "63b7ea81-03df-43ae-b708-630b9ce6722f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of each component: [1.65166368e-01 9.87588289e-02 7.57005618e-02 6.35219884e-02\n",
      " 5.57802410e-02 4.86490012e-02 3.84102860e-02 3.34387797e-02\n",
      " 3.07691390e-02 2.70696671e-02 2.63302922e-02 2.41029996e-02\n",
      " 2.19782326e-02 1.90622760e-02 1.79260583e-02 1.59391301e-02\n",
      " 1.45436295e-02 1.39761014e-02 1.34640442e-02 1.21452782e-02\n",
      " 1.08330940e-02 1.06239675e-02 9.60798090e-03 8.79655499e-03\n",
      " 8.52533044e-03 7.87058936e-03 7.68702381e-03 7.20932538e-03\n",
      " 6.63237785e-03 6.13358837e-03 5.67037149e-03 5.43375031e-03\n",
      " 4.95683418e-03 4.79072515e-03 4.52553928e-03 4.28500773e-03\n",
      " 4.05442846e-03 3.82641400e-03 3.64630833e-03 3.51883364e-03\n",
      " 3.19487600e-03 3.02262283e-03 2.96443991e-03 2.79389101e-03\n",
      " 2.69568877e-03 2.48184779e-03 2.28006155e-03 2.12838708e-03\n",
      " 2.02964634e-03 1.99753619e-03 1.78929675e-03 1.58131891e-03\n",
      " 1.54786735e-03 1.43197175e-03 1.38958624e-03 1.23759240e-03\n",
      " 1.21083670e-03 1.14813529e-03 1.09102996e-03 1.07955759e-03\n",
      " 9.86393147e-04 9.09726089e-04 8.21514910e-04 7.18393390e-04\n",
      " 6.88218523e-04 5.90007738e-04 5.70267800e-04 5.48852109e-04\n",
      " 4.92203098e-04 4.83042035e-04 4.51944978e-04 4.32779383e-04\n",
      " 4.06758569e-04 3.86516303e-04 3.71159380e-04 3.56262440e-04\n",
      " 3.36689253e-04 3.31606902e-04 3.07719891e-04 2.79684053e-04\n",
      " 2.73337696e-04 2.54115580e-04 2.41876416e-04 2.26765602e-04\n",
      " 2.18526582e-04 1.92218038e-04 1.83366311e-04 1.80582393e-04\n",
      " 1.66066226e-04 1.51638343e-04 1.49300392e-04 1.41714024e-04\n",
      " 1.26607740e-04 1.14039131e-04 1.11005861e-04 1.03242058e-04\n",
      " 9.85735960e-05 9.41373373e-05 9.03228043e-05 8.91440127e-05\n",
      " 8.51559275e-05 8.02178591e-05 7.35428547e-05 6.54581386e-05\n",
      " 6.42723735e-05 6.16419936e-05 5.97141616e-05 5.59069849e-05\n",
      " 5.40735350e-05 5.37379748e-05 5.02405066e-05 4.75559569e-05\n",
      " 4.44998641e-05 4.18088833e-05 3.86895673e-05 3.69460028e-05\n",
      " 3.60293322e-05 3.43015812e-05 3.37522936e-05 3.24073561e-05\n",
      " 3.04055864e-05 2.83130451e-05 2.77684106e-05 2.70651335e-05\n",
      " 2.60162538e-05 2.47071545e-05 2.40045585e-05 2.22087160e-05\n",
      " 2.13915023e-05 2.07934495e-05 2.00048542e-05 1.92122616e-05\n",
      " 1.85770942e-05 1.75776886e-05 1.68276139e-05 1.66143846e-05\n",
      " 1.57853176e-05 1.54635711e-05 1.43573336e-05 1.40963575e-05\n",
      " 1.34828832e-05 1.32968777e-05 1.26279211e-05 1.23305983e-05\n",
      " 1.18819614e-05 1.11027694e-05 1.06702951e-05 1.04353034e-05\n",
      " 1.00355520e-05 9.39770943e-06 9.24157388e-06 8.83183099e-06\n",
      " 8.37832435e-06 8.29288969e-06 8.10572070e-06 7.95602805e-06\n",
      " 7.66028563e-06 7.31685568e-06 6.97618823e-06 6.78706028e-06\n",
      " 6.64031652e-06 6.31280970e-06 6.21285988e-06 5.98067772e-06\n",
      " 5.71551061e-06 5.54376841e-06 5.51365907e-06 5.35683198e-06\n",
      " 5.17032759e-06 4.83087100e-06 4.71227859e-06 4.64091623e-06\n",
      " 4.28494178e-06 4.25356133e-06 4.16353503e-06 4.07014371e-06\n",
      " 3.88965777e-06 3.84189428e-06 3.70868783e-06 3.56851389e-06\n",
      " 3.51686181e-06 3.36729362e-06 3.27244940e-06 3.26097211e-06\n",
      " 3.09791989e-06 3.03093607e-06 2.94493184e-06 2.85863863e-06\n",
      " 2.69975043e-06 2.64797197e-06 2.58862128e-06 2.40564678e-06\n",
      " 2.35132771e-06 2.26202568e-06 2.16034693e-06 2.13938285e-06\n",
      " 2.03542476e-06 1.97972975e-06 1.90612210e-06 1.82436639e-06\n",
      " 1.81454705e-06 1.72326341e-06 1.68520989e-06 1.65796657e-06\n",
      " 1.60018337e-06 1.57539205e-06 1.51875704e-06 1.47771714e-06\n",
      " 1.46018049e-06 1.41570610e-06 1.39711169e-06 1.34526740e-06\n",
      " 1.32110803e-06 1.27335989e-06 1.22602606e-06 1.18385704e-06\n",
      " 1.13536878e-06 1.10480698e-06 1.04772965e-06 1.04336843e-06\n",
      " 1.02650311e-06 1.01725970e-06 9.75683258e-07 9.68533919e-07\n",
      " 8.92668988e-07 8.79629169e-07 8.59100483e-07 8.22438654e-07\n",
      " 7.97118236e-07 7.80822561e-07 7.63809072e-07 7.25616413e-07\n",
      " 7.01541914e-07 6.91414913e-07 6.71760438e-07 6.49556026e-07\n",
      " 6.23214689e-07 5.92031291e-07 5.70662961e-07 5.59712414e-07\n",
      " 5.25187907e-07 5.05501326e-07 4.94544127e-07 4.86866893e-07\n",
      " 4.40640304e-07 4.31108190e-07 4.21234325e-07 3.98666328e-07\n",
      " 3.87604195e-07 3.73163763e-07]\n",
      "\n",
      " Total Variance Explained: 100.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.208859</td>\n",
       "      <td>0.274351</td>\n",
       "      <td>0.190776</td>\n",
       "      <td>-1.752713</td>\n",
       "      <td>-1.112519</td>\n",
       "      <td>-0.274059</td>\n",
       "      <td>-0.863308</td>\n",
       "      <td>-0.440208</td>\n",
       "      <td>-0.526820</td>\n",
       "      <td>0.895038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>-0.001177</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108521</td>\n",
       "      <td>0.308966</td>\n",
       "      <td>-0.960386</td>\n",
       "      <td>0.042185</td>\n",
       "      <td>0.311407</td>\n",
       "      <td>0.044740</td>\n",
       "      <td>0.632528</td>\n",
       "      <td>0.690121</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.551882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>-0.001890</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.002038</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.671141</td>\n",
       "      <td>1.146752</td>\n",
       "      <td>1.190608</td>\n",
       "      <td>-0.983021</td>\n",
       "      <td>-0.782139</td>\n",
       "      <td>-0.284722</td>\n",
       "      <td>0.519356</td>\n",
       "      <td>0.335556</td>\n",
       "      <td>-0.327130</td>\n",
       "      <td>-1.030457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>-0.000552</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.001847</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.246962</td>\n",
       "      <td>-0.367193</td>\n",
       "      <td>-1.054057</td>\n",
       "      <td>0.318842</td>\n",
       "      <td>-1.179789</td>\n",
       "      <td>-1.641813</td>\n",
       "      <td>1.430781</td>\n",
       "      <td>-0.107672</td>\n",
       "      <td>-0.261268</td>\n",
       "      <td>0.115664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-0.000947</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.652776</td>\n",
       "      <td>1.248695</td>\n",
       "      <td>-0.329589</td>\n",
       "      <td>-0.160325</td>\n",
       "      <td>0.145818</td>\n",
       "      <td>-0.452044</td>\n",
       "      <td>0.396805</td>\n",
       "      <td>0.217702</td>\n",
       "      <td>0.079924</td>\n",
       "      <td>-0.452882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>-0.003090</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>-1.227579</td>\n",
       "      <td>0.830867</td>\n",
       "      <td>-0.861588</td>\n",
       "      <td>0.887840</td>\n",
       "      <td>-0.396637</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>-0.415588</td>\n",
       "      <td>1.129601</td>\n",
       "      <td>0.759303</td>\n",
       "      <td>0.785331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>-0.005212</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>-0.003692</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000881</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>3.171192</td>\n",
       "      <td>2.555394</td>\n",
       "      <td>-1.046524</td>\n",
       "      <td>-0.422312</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.556218</td>\n",
       "      <td>-0.373504</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>-0.120405</td>\n",
       "      <td>0.385478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>-0.003713</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0.172322</td>\n",
       "      <td>1.316051</td>\n",
       "      <td>-1.007987</td>\n",
       "      <td>-0.068652</td>\n",
       "      <td>-0.435990</td>\n",
       "      <td>0.137443</td>\n",
       "      <td>-0.243548</td>\n",
       "      <td>-0.001396</td>\n",
       "      <td>-0.219588</td>\n",
       "      <td>0.355723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001134</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>-1.855033</td>\n",
       "      <td>1.617573</td>\n",
       "      <td>0.097459</td>\n",
       "      <td>0.411804</td>\n",
       "      <td>-0.347820</td>\n",
       "      <td>0.148107</td>\n",
       "      <td>-0.226309</td>\n",
       "      <td>-0.031195</td>\n",
       "      <td>0.015719</td>\n",
       "      <td>-0.172554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>-0.003456</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.002725</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows Ã— 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -1.208859  0.274351  0.190776 -1.752713 -1.112519 -0.274059 -0.863308   \n",
       "1    0.108521  0.308966 -0.960386  0.042185  0.311407  0.044740  0.632528   \n",
       "2   -1.671141  1.146752  1.190608 -0.983021 -0.782139 -0.284722  0.519356   \n",
       "3   -0.246962 -0.367193 -1.054057  0.318842 -1.179789 -1.641813  1.430781   \n",
       "4    1.652776  1.248695 -0.329589 -0.160325  0.145818 -0.452044  0.396805   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "923 -1.227579  0.830867 -0.861588  0.887840 -0.396637 -0.491460 -0.415588   \n",
       "924  3.171192  2.555394 -1.046524 -0.422312  0.090090  0.556218 -0.373504   \n",
       "925  0.172322  1.316051 -1.007987 -0.068652 -0.435990  0.137443 -0.243548   \n",
       "926 -1.855033  1.617573  0.097459  0.411804 -0.347820  0.148107 -0.226309   \n",
       "927       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            7         8         9  ...       241       242       243  \\\n",
       "0   -0.440208 -0.526820  0.895038  ... -0.000845 -0.001177  0.000341   \n",
       "1    0.690121 -0.085436  0.551882  ...  0.001740  0.000778 -0.001890   \n",
       "2    0.335556 -0.327130 -1.030457  ...  0.001320 -0.000552  0.001386   \n",
       "3   -0.107672 -0.261268  0.115664  ...  0.003757 -0.000540 -0.000205   \n",
       "4    0.217702  0.079924 -0.452882  ... -0.000057 -0.000053  0.000574   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "923  1.129601  0.759303  0.785331  ... -0.001960 -0.005212 -0.000210   \n",
       "924  0.040195 -0.120405  0.385478  ...  0.002080  0.000694  0.001573   \n",
       "925 -0.001396 -0.219588  0.355723  ... -0.001134 -0.002301  0.000420   \n",
       "926 -0.031195  0.015719 -0.172554  ... -0.000812 -0.000779 -0.003456   \n",
       "927       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "          244       245       246       247       248       249  target  \n",
       "0   -0.002045  0.000443  0.001814 -0.001854 -0.000165 -0.001658       2  \n",
       "1   -0.001390 -0.001508 -0.002038 -0.002469 -0.000911  0.001341       2  \n",
       "2   -0.000255  0.000459 -0.001168  0.002141  0.001916 -0.001847       2  \n",
       "3    0.001002 -0.002062 -0.003845  0.000689 -0.001767 -0.000947       2  \n",
       "4    0.001680 -0.003090  0.002310  0.001286 -0.004728  0.000221       2  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "923  0.001707  0.003365 -0.000979 -0.003692 -0.000594 -0.000881       3  \n",
       "924  0.003479  0.000563  0.000813 -0.001520 -0.003713  0.000740       3  \n",
       "925  0.000191  0.001371  0.001320 -0.001330  0.001598  0.000219       3  \n",
       "926 -0.001329  0.000718 -0.002725  0.002457  0.000537  0.001468       3  \n",
       "927       NaN       NaN       NaN       NaN       NaN       NaN       3  \n",
       "\n",
       "[928 rows x 251 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now Perform Dimensionality reduction (PCA) on that Dataframe and check\n",
    "from sklearn.decomposition import PCA\n",
    "df = pd.read_csv('final_1d.csv')\n",
    "#do PCA and choose componeents as 400\n",
    "pca = PCA(n_components=250)\n",
    "x_pca = pca.fit_transform(df)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "\n",
    "# Calculate the variance explained by priciple components\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print('Variance of each component:', pca.explained_variance_ratio_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))\n",
    "\n",
    "#store the new pca generated dimensions in a dataframe\n",
    "#store the new pca generated dimensions in a dataframe\n",
    "pca_df = pd.DataFrame(data = x_pca)\n",
    "target = pd.Series(result_df.iloc[:,-1], name='target')\n",
    "final_result_df = pd.concat([pca_df, target], axis=1)\n",
    "final_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l93cv3DXjw2A"
   },
   "source": [
    "#### **TRYING DIFFERENT ML MODELS ON THE ALL 12 LEADS COMBINED FILE WITHOUT DIMENSIONALITY REDUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLAdjoV0j5oS"
   },
   "source": [
    "##### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Np5A0l30TYEI",
    "outputId": "9e5f4a0e-90d6-4853-a687-f4e69a70de1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9973118279569892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      0.99      0.99        94\n",
      "           2       1.00      1.00      1.00       112\n",
      "           3       0.98      1.00      0.99        61\n",
      "\n",
      "    accuracy                           1.00       372\n",
      "   macro avg       1.00      1.00      1.00       372\n",
      "weighted avg       1.00      1.00      1.00       372\n",
      "\n",
      "Tuned Model Parameters: {'knn__n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for ML model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "dataset= pd.read_csv('pca_final.csv')\n",
    "\n",
    "# Setup the pipeline steps:\n",
    "steps = [('knn', KNeighborsClassifier())]\n",
    "        \n",
    "# Create the pipeline: pipeline \n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# have paased less range value of hyperparamter since i'm using free tier version of google colab.\n",
    "k_range = list(range(1, 30))\n",
    "parameters = dict(knn__n_neighbors=k_range)\n",
    "\n",
    "#input\n",
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "#target\n",
    "y= dataset.iloc[:,-1]\n",
    "\n",
    "# Create train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "#increasing cv score takes lot of time in gooogle colab, so kept it just 2.\n",
    "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
    "\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "Knn_Accuracy = cv.score(X_test, y_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(Knn_Accuracy))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "METf9MJdkESh"
   },
   "source": [
    "##### **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3qBayEUskDfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "dataset= pd.read_csv('pca_final.csv')\n",
    "\n",
    "# Setup the pipeline steps:\n",
    "steps = [('lr', LogisticRegression())]\n",
    "        \n",
    "# Create the pipeline: pipeline \n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#input\n",
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "#target\n",
    "y= dataset.iloc[:,-1]\n",
    "\n",
    "#parameters for gridsearchcv\n",
    "c_space = np.logspace(-4, 4, 10)\n",
    "parameters = {'lr__C': c_space,'lr__penalty': ['l2']} \n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "#call GridSearchCV and set crossvalscore to 2\n",
    "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
    "\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "LR_Accuracy = cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xV9YlHZktj9",
    "outputId": "b6fc9558-a064-407b-ced4-c81e3aefbcee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9838709677419355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       105\n",
      "           1       1.00      0.98      0.99        94\n",
      "           2       0.97      1.00      0.98       112\n",
      "           3       0.97      1.00      0.98        61\n",
      "\n",
      "    accuracy                           0.98       372\n",
      "   macro avg       0.98      0.99      0.98       372\n",
      "weighted avg       0.98      0.98      0.98       372\n",
      "\n",
      "Tuned Model Parameters: {'lr__C': 0.0001, 'lr__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(LR_Accuracy))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOJDLUA6p5Xd"
   },
   "source": [
    "##### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yG0rz8crlJK5",
    "outputId": "a560d998-8fd8-4fe9-bac6-be22cda925b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9245689655172413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       119\n",
      "           1       1.00      0.89      0.94       125\n",
      "           2       0.81      1.00      0.89       140\n",
      "           3       1.00      0.75      0.86        80\n",
      "\n",
      "    accuracy                           0.92       464\n",
      "   macro avg       0.95      0.91      0.92       464\n",
      "weighted avg       0.94      0.92      0.92       464\n",
      "\n",
      "Tuned Model Parameters: {'SVM__C': 10, 'SVM__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for ML model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Setup the pipeline\n",
    "steps = [('SVM', SVC())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#input\n",
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "#target\n",
    "y=dataset.iloc[:,-1]\n",
    "\n",
    "# Specify the hyperparameter space, if we increase the penalty(c) and gamma value the accurancy can be increased.\n",
    "#since it takes lots of time in google colab provided only a single value\n",
    "parameters = {'SVM__C':[1, 10],\n",
    "              'SVM__gamma':[0.1, 0.01]}\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5,random_state=21)\n",
    "\n",
    "cv = GridSearchCV(pipeline,parameters,cv=3)\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "SVM_Accuracy = cv.score(X_test, y_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "SVM_Accuracy=cv.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy: {}\".format(SVM_Accuracy))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqxwP-4vIbbm"
   },
   "source": [
    "### **XGBOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "4xWCZUjyIWoJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "bzdU_OL7IY0U"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OY33WUdIapb",
    "outputId": "40e112ea-0807-47bc-a873-0bdeeca4f0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9956896551724138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       119\n",
      "           1       1.00      0.99      1.00       125\n",
      "           2       1.00      0.99      1.00       140\n",
      "           3       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00       464\n",
      "   macro avg       1.00      1.00      1.00       464\n",
      "weighted avg       1.00      1.00      1.00       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izUvTTDBp-Vy"
   },
   "source": [
    "#### **SAVING A VERY BASIC ML MODEL AND USING IT ON REALTIME PIPELINE TO CHECK WORKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN7RIL_3PnJb",
    "outputId": "6bcad7b1-cfbc-4066-f8c2-5404e4e6da11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_model_test.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules for ML model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import joblib\n",
    "#input\n",
    "X = dataset.iloc[:,:-1]\n",
    "#target\n",
    "y=dataset.iloc[:,-1]\n",
    "\n",
    "# Create train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "knn =  KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "joblib_file='knn_model_test.pkl'\n",
    "joblib.dump(knn,joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNiBzgDv_-oA",
    "outputId": "e68d2bfc-1935-404e-de27-3628e2d9e0c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model_test.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules for ML model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "dataset= pd.read_csv('pca_final.csv')\n",
    "\n",
    "#input\n",
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "#target\n",
    "y=dataset.iloc[:,-1]\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5,random_state=21)\n",
    "\n",
    "svm=SVC(C=10,gamma=0.01)\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "\n",
    "joblib_file='svm_model_test.pkl'\n",
    "joblib.dump(svm,joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmKRxfCBH7Yo"
   },
   "source": [
    "### **ENSEMBLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "7V2P-WtiYZ4f"
   },
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "from sklearn import linear_model, tree, ensemble\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "eA1TkdrcYZ4g"
   },
   "outputs": [],
   "source": [
    "#input\n",
    "data = pd.read_csv('final_1D.csv')\n",
    "X = data.iloc[:,0:-1]\n",
    "\n",
    "#target\n",
    "y=data.iloc[:,-1]\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "A4caey39YZ4f"
   },
   "outputs": [],
   "source": [
    "# Stacking of ML Models\n",
    "eclf = VotingClassifier(estimators=[ \n",
    "    ('SVM', SVC(probability=True)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('rf', ensemble.RandomForestClassifier()),\n",
    "    ('bayes',GaussianNB()),\n",
    "    ('logistic',LogisticRegression()),\n",
    "    ], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "neqxcy3GqS91",
    "outputId": "5acb921a-9719-4836-8ef2-4b7ba370e27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM__C': 10, 'SVM__gamma': 0.1, 'knn__n_neighbors': 1, 'rf__n_estimators': 300}\n",
      "Accuracy: 0.8530465949820788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.80        79\n",
      "           1       0.90      1.00      0.95        73\n",
      "           2       0.81      0.91      0.86        79\n",
      "           3       0.83      0.71      0.76        48\n",
      "\n",
      "    accuracy                           0.85       279\n",
      "   macro avg       0.85      0.84      0.84       279\n",
      "weighted avg       0.85      0.85      0.85       279\n",
      "\n",
      "{'SVM__C': 10, 'SVM__gamma': 0.1, 'knn__n_neighbors': 1, 'rf__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using gridSearch\n",
    "params = {'SVM__C':[1, 10, 100],\n",
    "          'SVM__gamma':[0.1, 0.01],\n",
    "          'knn__n_neighbors': [1,3,5],\n",
    "          'rf__n_estimators':[300, 400],\n",
    "          }\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "voting_clf = grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "Voting_Accuracy=voting_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy: {}\".format(Voting_Accuracy))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(voting_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "91lBO_ZUYZ4j"
   },
   "outputs": [],
   "source": [
    "# open a file, where you ant to store the data\n",
    "file = open('Heart_Disease_Prediction_using_ECG.pkl', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(voting_clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emu__tW7qP9b"
   },
   "source": [
    "## SAVE AND USE THE ABOVE MODEL IN THE STREAMLIT APP : **https://colab.research.google.com/drive/139YVmcUBCiP52J2sX3QE_eiu2sukVgpn?usp=sharing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Merging_Scaled_1D_&_Trying_Different_CLassification_ML_Models_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
